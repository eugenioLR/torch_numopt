{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.5174350738525391\n",
      "epoch:  1, loss: 0.06672327220439911\n",
      "epoch:  2, loss: 0.03232215344905853\n",
      "epoch:  3, loss: 0.02538452297449112\n",
      "epoch:  4, loss: 0.017865171656012535\n",
      "epoch:  5, loss: 0.01703009195625782\n",
      "epoch:  6, loss: 0.011467866599559784\n",
      "epoch:  7, loss: 0.010719282552599907\n",
      "epoch:  8, loss: 0.00985685270279646\n",
      "epoch:  9, loss: 0.009250903502106667\n",
      "epoch:  10, loss: 0.008748169057071209\n",
      "epoch:  11, loss: 0.008593478240072727\n",
      "epoch:  12, loss: 0.006469870917499065\n",
      "epoch:  13, loss: 0.0058463201858103275\n",
      "epoch:  14, loss: 0.0057974462397396564\n",
      "epoch:  15, loss: 0.00461881747469306\n",
      "epoch:  16, loss: 0.0043914406560361385\n",
      "epoch:  17, loss: 0.003793660318478942\n",
      "epoch:  18, loss: 0.003650564467534423\n",
      "epoch:  19, loss: 0.002931748516857624\n",
      "epoch:  20, loss: 0.002633826807141304\n",
      "epoch:  21, loss: 0.002433792455121875\n",
      "epoch:  22, loss: 0.0021935426630079746\n",
      "epoch:  23, loss: 0.002015691017732024\n",
      "epoch:  24, loss: 0.0019404221093282104\n",
      "epoch:  25, loss: 0.0019106685649603605\n",
      "epoch:  26, loss: 0.0018234194722026587\n",
      "epoch:  27, loss: 0.0017440947704017162\n",
      "epoch:  28, loss: 0.0016774837858974934\n",
      "epoch:  29, loss: 0.0015850155614316463\n",
      "epoch:  30, loss: 0.0015760507667437196\n",
      "epoch:  31, loss: 0.0013979703653603792\n",
      "epoch:  32, loss: 0.0013457643799483776\n",
      "epoch:  33, loss: 0.0013143963878974319\n",
      "epoch:  34, loss: 0.001246006228029728\n",
      "epoch:  35, loss: 0.0011939792893826962\n",
      "epoch:  36, loss: 0.0011325187515467405\n",
      "epoch:  37, loss: 0.0010981358354911208\n",
      "epoch:  38, loss: 0.0010432528797537088\n",
      "epoch:  39, loss: 0.0010179769014939666\n",
      "epoch:  40, loss: 0.0009676636545918882\n",
      "epoch:  41, loss: 0.0009568104287609458\n",
      "epoch:  42, loss: 0.0009127237717621028\n",
      "epoch:  43, loss: 0.0008986832690425217\n",
      "epoch:  44, loss: 0.0008897679508663714\n",
      "epoch:  45, loss: 0.0008890197495929897\n",
      "epoch:  46, loss: 0.0008596350089646876\n",
      "epoch:  47, loss: 0.0008581302827224135\n",
      "epoch:  48, loss: 0.0008284017676487565\n",
      "epoch:  49, loss: 0.000821359921246767\n",
      "epoch:  50, loss: 0.0007937691989354789\n",
      "epoch:  51, loss: 0.0007915558526292443\n",
      "epoch:  52, loss: 0.000764165073633194\n",
      "epoch:  53, loss: 0.0007587221916764975\n",
      "epoch:  54, loss: 0.0007339848671108484\n",
      "epoch:  55, loss: 0.0007337927236221731\n",
      "epoch:  56, loss: 0.0007119881920516491\n",
      "epoch:  57, loss: 0.0007105620461516082\n",
      "epoch:  58, loss: 0.0006899266154505312\n",
      "epoch:  59, loss: 0.0006838150438852608\n",
      "epoch:  60, loss: 0.0006808575708419085\n",
      "epoch:  61, loss: 0.0006731705507263541\n",
      "epoch:  62, loss: 0.0006665911059826612\n",
      "epoch:  63, loss: 0.0006589863914996386\n",
      "epoch:  64, loss: 0.0006546266959048808\n",
      "epoch:  65, loss: 0.0006479104631580412\n",
      "epoch:  66, loss: 0.0006455239490605891\n",
      "epoch:  67, loss: 0.0006389966001734138\n",
      "epoch:  68, loss: 0.000636923243291676\n",
      "epoch:  69, loss: 0.0006303382688201964\n",
      "epoch:  70, loss: 0.0006239122012630105\n",
      "epoch:  71, loss: 0.0006227686535567045\n",
      "epoch:  72, loss: 0.0006108834058977664\n",
      "epoch:  73, loss: 0.0006065526395104825\n",
      "epoch:  74, loss: 0.0005943804862909019\n",
      "epoch:  75, loss: 0.0005888689192943275\n",
      "epoch:  76, loss: 0.0005773231969214976\n",
      "epoch:  77, loss: 0.0005708716344088316\n",
      "epoch:  78, loss: 0.0005595885450020432\n",
      "epoch:  79, loss: 0.0005505610024556518\n",
      "epoch:  80, loss: 0.0005483947461470962\n",
      "epoch:  81, loss: 0.0005288566462695599\n",
      "epoch:  82, loss: 0.0005269445828162134\n",
      "epoch:  83, loss: 0.0005092982319183648\n",
      "epoch:  84, loss: 0.0005089842015877366\n",
      "epoch:  85, loss: 0.0004933263990096748\n",
      "epoch:  86, loss: 0.000488611520268023\n",
      "epoch:  87, loss: 0.00048514135414734483\n",
      "epoch:  88, loss: 0.00048504621372558177\n",
      "epoch:  89, loss: 0.00047459269990213215\n",
      "epoch:  90, loss: 0.0004700531717389822\n",
      "epoch:  91, loss: 0.00045859639067202806\n",
      "epoch:  92, loss: 0.00044848580728285015\n",
      "epoch:  93, loss: 0.00044841598719358444\n",
      "epoch:  94, loss: 0.0004284610622562468\n",
      "epoch:  95, loss: 0.00042720750207081437\n",
      "epoch:  96, loss: 0.0004092007875442505\n",
      "epoch:  97, loss: 0.0004037348844576627\n",
      "epoch:  98, loss: 0.0003999146574642509\n",
      "epoch:  99, loss: 0.0003997350577265024\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.AGD(\n",
    "    model.parameters(),\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    model=model,\n",
    "    use_diagonal=False,\n",
    "    c1=1e-4,\n",
    "    tau=0.5,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "all_loss = []\n",
    "patience = 0\n",
    "max_patience = 10\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss.append(0)\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch] += loss\n",
    "\n",
    "    all_loss[epoch] /= len(data_loader)\n",
    "\n",
    "    if epoch > 0 and all_loss[epoch - 1] <= all_loss[epoch]:\n",
    "        patience -= 1\n",
    "    else:\n",
    "        patience = max_patience\n",
    "\n",
    "    print(\", loss: {}\".format(all_loss[epoch].detach().cpu().numpy().item()))\n",
    "\n",
    "    if patience <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.988854822157648\n",
      "Test metrics:  R2 = 0.9868933637297932\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.17654085159301758\n",
      "epoch:  1, loss: 0.02821688912808895\n",
      "epoch:  2, loss: 0.02365739829838276\n",
      "epoch:  3, loss: 0.010598459281027317\n",
      "epoch:  4, loss: 0.009633749723434448\n",
      "epoch:  5, loss: 0.00860026478767395\n",
      "epoch:  6, loss: 0.007722286973148584\n",
      "epoch:  7, loss: 0.007204593624919653\n",
      "epoch:  8, loss: 0.006601330824196339\n",
      "epoch:  9, loss: 0.0061677913181483746\n",
      "epoch:  10, loss: 0.005742161069065332\n",
      "epoch:  11, loss: 0.005486208945512772\n",
      "epoch:  12, loss: 0.005222318693995476\n",
      "epoch:  13, loss: 0.0050088874995708466\n",
      "epoch:  14, loss: 0.004778837785124779\n",
      "epoch:  15, loss: 0.004520828370004892\n",
      "epoch:  16, loss: 0.004188455641269684\n",
      "epoch:  17, loss: 0.0038940904196351767\n",
      "epoch:  18, loss: 0.0036144577898085117\n",
      "epoch:  19, loss: 0.003386372933164239\n",
      "epoch:  20, loss: 0.003162921406328678\n",
      "epoch:  21, loss: 0.002991692628711462\n",
      "epoch:  22, loss: 0.002902550157159567\n",
      "epoch:  23, loss: 0.0021084703039377928\n",
      "epoch:  24, loss: 0.0018627080135047436\n",
      "epoch:  25, loss: 0.0017172977095469832\n",
      "epoch:  26, loss: 0.0015640869969502091\n",
      "epoch:  27, loss: 0.001400223933160305\n",
      "epoch:  28, loss: 0.0012345784343779087\n",
      "epoch:  29, loss: 0.0010903372894972563\n",
      "epoch:  30, loss: 0.0009748248849064112\n",
      "epoch:  31, loss: 0.0008840015507303178\n",
      "epoch:  32, loss: 0.0008027673466131091\n",
      "epoch:  33, loss: 0.0005558582488447428\n",
      "epoch:  34, loss: 0.00047911546425893903\n",
      "epoch:  35, loss: 0.00043742655543610454\n",
      "epoch:  36, loss: 0.00041021755896508694\n",
      "epoch:  37, loss: 0.00035147526068612933\n",
      "epoch:  38, loss: 0.00030028342735022306\n",
      "epoch:  39, loss: 0.0002802628150675446\n",
      "epoch:  40, loss: 0.0002674295683391392\n",
      "epoch:  41, loss: 0.0002440853277221322\n",
      "epoch:  42, loss: 0.00022344139870256186\n",
      "epoch:  43, loss: 0.00021377824305091053\n",
      "epoch:  44, loss: 0.00020157606923021376\n",
      "epoch:  45, loss: 0.00018641930364537984\n",
      "epoch:  46, loss: 0.00017892687174025923\n",
      "epoch:  47, loss: 0.0001744005421642214\n",
      "epoch:  48, loss: 0.0001644080621190369\n",
      "epoch:  49, loss: 0.0001551248278701678\n",
      "epoch:  50, loss: 0.00015149806858971715\n",
      "epoch:  51, loss: 0.00014496773655992\n",
      "epoch:  52, loss: 0.0001377111184410751\n",
      "epoch:  53, loss: 0.00013428268721327186\n",
      "epoch:  54, loss: 0.00012978800805285573\n",
      "epoch:  55, loss: 0.0001225937157869339\n",
      "epoch:  56, loss: 0.00011975849338341504\n",
      "epoch:  57, loss: 0.00011795765021815896\n",
      "epoch:  58, loss: 0.00011416115012252703\n",
      "epoch:  59, loss: 0.00011106511374237016\n",
      "epoch:  60, loss: 0.00010942999506369233\n",
      "epoch:  61, loss: 0.000105665298178792\n",
      "epoch:  62, loss: 0.00010260184353683144\n",
      "epoch:  63, loss: 0.00010112713789567351\n",
      "epoch:  64, loss: 0.00010026413656305522\n",
      "epoch:  65, loss: 9.770036558620632e-05\n",
      "epoch:  66, loss: 9.632991714170203e-05\n",
      "epoch:  67, loss: 9.627546387491748e-05\n",
      "epoch:  68, loss: 9.311328904004768e-05\n",
      "epoch:  69, loss: 9.188598050968722e-05\n",
      "epoch:  70, loss: 9.165754454443231e-05\n",
      "epoch:  71, loss: 8.891413745004684e-05\n",
      "epoch:  72, loss: 8.766947576077655e-05\n",
      "epoch:  73, loss: 8.696889562997967e-05\n",
      "epoch:  74, loss: 8.569091733079404e-05\n",
      "epoch:  75, loss: 8.417009667027742e-05\n",
      "epoch:  76, loss: 8.341576904058456e-05\n",
      "epoch:  77, loss: 8.266629447462037e-05\n",
      "epoch:  78, loss: 8.106330642476678e-05\n",
      "epoch:  79, loss: 8.025794522836804e-05\n",
      "epoch:  80, loss: 7.976505730766803e-05\n",
      "epoch:  81, loss: 7.798457227181643e-05\n",
      "epoch:  82, loss: 7.716868276474997e-05\n",
      "epoch:  83, loss: 7.700475543970242e-05\n",
      "epoch:  84, loss: 7.534454925917089e-05\n",
      "epoch:  85, loss: 7.453897706000134e-05\n",
      "epoch:  86, loss: 7.408440433209762e-05\n",
      "epoch:  87, loss: 7.392736006295308e-05\n",
      "epoch:  88, loss: 7.28670202079229e-05\n",
      "epoch:  89, loss: 7.237573299789801e-05\n",
      "epoch:  90, loss: 7.208134775282815e-05\n",
      "epoch:  91, loss: 7.173015183070675e-05\n",
      "epoch:  92, loss: 7.117633504094556e-05\n",
      "epoch:  93, loss: 7.09041632944718e-05\n",
      "epoch:  94, loss: 7.069843559293076e-05\n",
      "epoch:  95, loss: 7.020236807875335e-05\n",
      "epoch:  96, loss: 6.995540024945512e-05\n",
      "epoch:  97, loss: 6.978560122661293e-05\n",
      "epoch:  98, loss: 6.9763271312695e-05\n",
      "epoch:  99, loss: 6.936253339517862e-05\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.AGD(\n",
    "    model.parameters(),\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    model=model,\n",
    "    use_diagonal=True,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "all_loss = []\n",
    "patience = 0\n",
    "max_patience = 10\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss.append(0)\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch] += loss\n",
    "\n",
    "    all_loss[epoch] /= len(data_loader)\n",
    "\n",
    "    if epoch > 0 and all_loss[epoch - 1] <= all_loss[epoch]:\n",
    "        patience -= 1\n",
    "    else:\n",
    "        patience = max_patience\n",
    "\n",
    "    print(\", loss: {}\".format(all_loss[epoch].detach().cpu().numpy().item()))\n",
    "\n",
    "    if patience <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.998035684483543\n",
      "Test metrics:  R2 = 0.9973266055840903\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
