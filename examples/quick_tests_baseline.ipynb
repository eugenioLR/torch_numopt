{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.38649848103523254\n",
      "epoch:  1, loss: 0.35312575101852417\n",
      "epoch:  2, loss: 0.32293909788131714\n",
      "epoch:  3, loss: 0.29563575983047485\n",
      "epoch:  4, loss: 0.27096229791641235\n",
      "epoch:  5, loss: 0.2488178014755249\n",
      "epoch:  6, loss: 0.22895927727222443\n",
      "epoch:  7, loss: 0.21101608872413635\n",
      "epoch:  8, loss: 0.19470717012882233\n",
      "epoch:  9, loss: 0.17985931038856506\n",
      "epoch:  10, loss: 0.16633912920951843\n",
      "epoch:  11, loss: 0.1540299355983734\n",
      "epoch:  12, loss: 0.14282579720020294\n",
      "epoch:  13, loss: 0.13263137638568878\n",
      "epoch:  14, loss: 0.12335719913244247\n",
      "epoch:  15, loss: 0.11492391675710678\n",
      "epoch:  16, loss: 0.10725942254066467\n",
      "epoch:  17, loss: 0.10029556602239609\n",
      "epoch:  18, loss: 0.0939723327755928\n",
      "epoch:  19, loss: 0.08823325484991074\n",
      "epoch:  20, loss: 0.08302566409111023\n",
      "epoch:  21, loss: 0.07830239832401276\n",
      "epoch:  22, loss: 0.07402035593986511\n",
      "epoch:  23, loss: 0.07013946771621704\n",
      "epoch:  24, loss: 0.066623255610466\n",
      "epoch:  25, loss: 0.06343888491392136\n",
      "epoch:  26, loss: 0.06055612862110138\n",
      "epoch:  27, loss: 0.05794743075966835\n",
      "epoch:  28, loss: 0.05558759719133377\n",
      "epoch:  29, loss: 0.05345340818166733\n",
      "epoch:  30, loss: 0.05152413249015808\n",
      "epoch:  31, loss: 0.04978073015809059\n",
      "epoch:  32, loss: 0.04820578917860985\n",
      "epoch:  33, loss: 0.04678351432085037\n",
      "epoch:  34, loss: 0.04549964889883995\n",
      "epoch:  35, loss: 0.04434081166982651\n",
      "epoch:  36, loss: 0.04329516366124153\n",
      "epoch:  37, loss: 0.042351894080638885\n",
      "epoch:  38, loss: 0.04150122031569481\n",
      "epoch:  39, loss: 0.040734272450208664\n",
      "epoch:  40, loss: 0.040042996406555176\n",
      "epoch:  41, loss: 0.039420079439878464\n",
      "epoch:  42, loss: 0.038858868181705475\n",
      "epoch:  43, loss: 0.03835335373878479\n",
      "epoch:  44, loss: 0.037898093461990356\n",
      "epoch:  45, loss: 0.0374881811439991\n",
      "epoch:  46, loss: 0.03711913898587227\n",
      "epoch:  47, loss: 0.036786988377571106\n",
      "epoch:  48, loss: 0.03648809343576431\n",
      "epoch:  49, loss: 0.03621917963027954\n",
      "epoch:  50, loss: 0.03597724065184593\n",
      "epoch:  51, loss: 0.035759616643190384\n",
      "epoch:  52, loss: 0.03556389361619949\n",
      "epoch:  53, loss: 0.03538786992430687\n",
      "epoch:  54, loss: 0.035229574888944626\n",
      "epoch:  55, loss: 0.035087257623672485\n",
      "epoch:  56, loss: 0.03495931997895241\n",
      "epoch:  57, loss: 0.03484436124563217\n",
      "epoch:  58, loss: 0.034741032868623734\n",
      "epoch:  59, loss: 0.034648165106773376\n",
      "epoch:  60, loss: 0.034564703702926636\n",
      "epoch:  61, loss: 0.034489706158638\n",
      "epoch:  62, loss: 0.03442232683300972\n",
      "epoch:  63, loss: 0.03436179831624031\n",
      "epoch:  64, loss: 0.03430739790201187\n",
      "epoch:  65, loss: 0.03425849601626396\n",
      "epoch:  66, loss: 0.0342145599424839\n",
      "epoch:  67, loss: 0.03417506814002991\n",
      "epoch:  68, loss: 0.034139592200517654\n",
      "epoch:  69, loss: 0.03410770744085312\n",
      "epoch:  70, loss: 0.03407904878258705\n",
      "epoch:  71, loss: 0.03405328094959259\n",
      "epoch:  72, loss: 0.03403012454509735\n",
      "epoch:  73, loss: 0.03400930389761925\n",
      "epoch:  74, loss: 0.03399057686328888\n",
      "epoch:  75, loss: 0.03397373855113983\n",
      "epoch:  76, loss: 0.03395857289433479\n",
      "epoch:  77, loss: 0.033944930881261826\n",
      "epoch:  78, loss: 0.0339326485991478\n",
      "epoch:  79, loss: 0.03392159566283226\n",
      "epoch:  80, loss: 0.03391164168715477\n",
      "epoch:  81, loss: 0.03390267491340637\n",
      "epoch:  82, loss: 0.03389459103345871\n",
      "epoch:  83, loss: 0.03388730436563492\n",
      "epoch:  84, loss: 0.033880725502967834\n",
      "epoch:  85, loss: 0.03387479484081268\n",
      "epoch:  86, loss: 0.033869434148073196\n",
      "epoch:  87, loss: 0.0338645838201046\n",
      "epoch:  88, loss: 0.03386019915342331\n",
      "epoch:  89, loss: 0.03385623171925545\n",
      "epoch:  90, loss: 0.03385264426469803\n",
      "epoch:  91, loss: 0.03384938836097717\n",
      "epoch:  92, loss: 0.033846430480480194\n",
      "epoch:  93, loss: 0.033843744546175\n",
      "epoch:  94, loss: 0.033841297030448914\n",
      "epoch:  95, loss: 0.033839061856269836\n",
      "epoch:  96, loss: 0.033837031573057175\n",
      "epoch:  97, loss: 0.033835165202617645\n",
      "epoch:  98, loss: 0.03383345901966095\n",
      "epoch:  99, loss: 0.033831898123025894\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=2e-2)\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step()\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().cpu().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = -2066.6998586749505\n",
      "Test metrics:  R2 = -1994.3515784509143\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.04847664758563042\n",
      "epoch:  1, loss: 0.035514701157808304\n",
      "epoch:  2, loss: 0.03273080661892891\n",
      "epoch:  3, loss: 0.03723014518618584\n",
      "epoch:  4, loss: 0.036663856357336044\n",
      "epoch:  5, loss: 0.03359885513782501\n",
      "epoch:  6, loss: 0.03178165853023529\n",
      "epoch:  7, loss: 0.03187888488173485\n",
      "epoch:  8, loss: 0.0327356792986393\n",
      "epoch:  9, loss: 0.03324923664331436\n",
      "epoch:  10, loss: 0.03297702223062515\n",
      "epoch:  11, loss: 0.03205196559429169\n",
      "epoch:  12, loss: 0.030920229852199554\n",
      "epoch:  13, loss: 0.03010989911854267\n",
      "epoch:  14, loss: 0.02990950085222721\n",
      "epoch:  15, loss: 0.030062012374401093\n",
      "epoch:  16, loss: 0.029998019337654114\n",
      "epoch:  17, loss: 0.029340120032429695\n",
      "epoch:  18, loss: 0.028260523453354836\n",
      "epoch:  19, loss: 0.02719656005501747\n",
      "epoch:  20, loss: 0.026400625705718994\n",
      "epoch:  21, loss: 0.02576613612473011\n",
      "epoch:  22, loss: 0.024950813502073288\n",
      "epoch:  23, loss: 0.02371724136173725\n",
      "epoch:  24, loss: 0.022224897518754005\n",
      "epoch:  25, loss: 0.020941222086548805\n",
      "epoch:  26, loss: 0.019880428910255432\n",
      "epoch:  27, loss: 0.018326079472899437\n",
      "epoch:  28, loss: 0.01638205349445343\n",
      "epoch:  29, loss: 0.01523809228092432\n",
      "epoch:  30, loss: 0.014394699595868587\n",
      "epoch:  31, loss: 0.013236518949270248\n",
      "epoch:  32, loss: 0.013021282851696014\n",
      "epoch:  33, loss: 0.012485669925808907\n",
      "epoch:  34, loss: 0.012213020585477352\n",
      "epoch:  35, loss: 0.012123980559408665\n",
      "epoch:  36, loss: 0.011616060510277748\n",
      "epoch:  37, loss: 0.011524390429258347\n",
      "epoch:  38, loss: 0.010858348570764065\n",
      "epoch:  39, loss: 0.010589883662760258\n",
      "epoch:  40, loss: 0.010016262531280518\n",
      "epoch:  41, loss: 0.009669959545135498\n",
      "epoch:  42, loss: 0.009367797523736954\n",
      "epoch:  43, loss: 0.009118607267737389\n",
      "epoch:  44, loss: 0.0090707466006279\n",
      "epoch:  45, loss: 0.00887836329638958\n",
      "epoch:  46, loss: 0.008906456641852856\n",
      "epoch:  47, loss: 0.008721989579498768\n",
      "epoch:  48, loss: 0.008711145259439945\n",
      "epoch:  49, loss: 0.008525945246219635\n",
      "epoch:  50, loss: 0.008496510796248913\n",
      "epoch:  51, loss: 0.008313536643981934\n",
      "epoch:  52, loss: 0.008339702151715755\n",
      "epoch:  53, loss: 0.0082408981397748\n",
      "epoch:  54, loss: 0.00825594738125801\n",
      "epoch:  55, loss: 0.008259577676653862\n",
      "epoch:  56, loss: 0.008191294968128204\n",
      "epoch:  57, loss: 0.008203793317079544\n",
      "epoch:  58, loss: 0.008141742087900639\n",
      "epoch:  59, loss: 0.008118060417473316\n",
      "epoch:  60, loss: 0.00812707282602787\n",
      "epoch:  61, loss: 0.008091744035482407\n",
      "epoch:  62, loss: 0.008113401010632515\n",
      "epoch:  63, loss: 0.008102450519800186\n",
      "epoch:  64, loss: 0.008108154870569706\n",
      "epoch:  65, loss: 0.008109589107334614\n",
      "epoch:  66, loss: 0.008093070238828659\n",
      "epoch:  67, loss: 0.008095992729067802\n",
      "epoch:  68, loss: 0.008076297119259834\n",
      "epoch:  69, loss: 0.008077019825577736\n",
      "epoch:  70, loss: 0.008068817667663097\n",
      "epoch:  71, loss: 0.008055411279201508\n",
      "epoch:  72, loss: 0.00805754866451025\n",
      "epoch:  73, loss: 0.00803930964320898\n",
      "epoch:  74, loss: 0.008026516065001488\n",
      "epoch:  75, loss: 0.008024170994758606\n",
      "epoch:  76, loss: 0.00800448376685381\n",
      "epoch:  77, loss: 0.007993126288056374\n",
      "epoch:  78, loss: 0.007987706921994686\n",
      "epoch:  79, loss: 0.007971771992743015\n",
      "epoch:  80, loss: 0.007964814081788063\n",
      "epoch:  81, loss: 0.007955793291330338\n",
      "epoch:  82, loss: 0.007937601767480373\n",
      "epoch:  83, loss: 0.007923501543700695\n",
      "epoch:  84, loss: 0.007910950109362602\n",
      "epoch:  85, loss: 0.007892400026321411\n",
      "epoch:  86, loss: 0.007876248098909855\n",
      "epoch:  87, loss: 0.007866039872169495\n",
      "epoch:  88, loss: 0.00785157922655344\n",
      "epoch:  89, loss: 0.007829736918210983\n",
      "epoch:  90, loss: 0.00780680775642395\n",
      "epoch:  91, loss: 0.0077895671129226685\n",
      "epoch:  92, loss: 0.007774244528263807\n",
      "epoch:  93, loss: 0.007754040881991386\n",
      "epoch:  94, loss: 0.00772797642275691\n",
      "epoch:  95, loss: 0.007701929192990065\n",
      "epoch:  96, loss: 0.007676911540329456\n",
      "epoch:  97, loss: 0.007649660110473633\n",
      "epoch:  98, loss: 0.007616451010107994\n",
      "epoch:  99, loss: 0.007584458217024803\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step()\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().cpu().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.7083075638486611\n",
      "Test metrics:  R2 = 0.7475086476072998\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
