{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.2982991635799408\n",
      "epoch:  1, loss: 0.2728068232536316\n",
      "epoch:  2, loss: 0.24976131319999695\n",
      "epoch:  3, loss: 0.22895631194114685\n",
      "epoch:  4, loss: 0.2102551907300949\n",
      "epoch:  5, loss: 0.19349995255470276\n",
      "epoch:  6, loss: 0.17844733595848083\n",
      "epoch:  7, loss: 0.164863720536232\n",
      "epoch:  8, loss: 0.15257015824317932\n",
      "epoch:  9, loss: 0.14142927527427673\n",
      "epoch:  10, loss: 0.13132351636886597\n",
      "epoch:  11, loss: 0.12215439975261688\n",
      "epoch:  12, loss: 0.11383365839719772\n",
      "epoch:  13, loss: 0.10628622025251389\n",
      "epoch:  14, loss: 0.09944295883178711\n",
      "epoch:  15, loss: 0.09324000030755997\n",
      "epoch:  16, loss: 0.08762012422084808\n",
      "epoch:  17, loss: 0.08252923935651779\n",
      "epoch:  18, loss: 0.07791908830404282\n",
      "epoch:  19, loss: 0.07374623417854309\n",
      "epoch:  20, loss: 0.0699709802865982\n",
      "epoch:  21, loss: 0.06655686348676682\n",
      "epoch:  22, loss: 0.06347063183784485\n",
      "epoch:  23, loss: 0.06068222597241402\n",
      "epoch:  24, loss: 0.058163899928331375\n",
      "epoch:  25, loss: 0.055890753865242004\n",
      "epoch:  26, loss: 0.05383966863155365\n",
      "epoch:  27, loss: 0.05198948457837105\n",
      "epoch:  28, loss: 0.05032121017575264\n",
      "epoch:  29, loss: 0.04881754890084267\n",
      "epoch:  30, loss: 0.04746270179748535\n",
      "epoch:  31, loss: 0.0462423600256443\n",
      "epoch:  32, loss: 0.045143529772758484\n",
      "epoch:  33, loss: 0.04415446147322655\n",
      "epoch:  34, loss: 0.04326450824737549\n",
      "epoch:  35, loss: 0.0424639992415905\n",
      "epoch:  36, loss: 0.04174418747425079\n",
      "epoch:  37, loss: 0.04109708219766617\n",
      "epoch:  38, loss: 0.04051544517278671\n",
      "epoch:  39, loss: 0.03999282047152519\n",
      "epoch:  40, loss: 0.03952329233288765\n",
      "epoch:  41, loss: 0.03910158947110176\n",
      "epoch:  42, loss: 0.038722891360521317\n",
      "epoch:  43, loss: 0.038382865488529205\n",
      "epoch:  44, loss: 0.03807762265205383\n",
      "epoch:  45, loss: 0.03780362010002136\n",
      "epoch:  46, loss: 0.03755771741271019\n",
      "epoch:  47, loss: 0.03733709082007408\n",
      "epoch:  48, loss: 0.03713914006948471\n",
      "epoch:  49, loss: 0.03696155175566673\n",
      "epoch:  50, loss: 0.03680223599076271\n",
      "epoch:  51, loss: 0.036659304052591324\n",
      "epoch:  52, loss: 0.03653109073638916\n",
      "epoch:  53, loss: 0.03641607612371445\n",
      "epoch:  54, loss: 0.03631289675831795\n",
      "epoch:  55, loss: 0.03622034192085266\n",
      "epoch:  56, loss: 0.036137308925390244\n",
      "epoch:  57, loss: 0.036062803119421005\n",
      "epoch:  58, loss: 0.03599594533443451\n",
      "epoch:  59, loss: 0.03593594208359718\n",
      "epoch:  60, loss: 0.03588208183646202\n",
      "epoch:  61, loss: 0.03583372011780739\n",
      "epoch:  62, loss: 0.03579028695821762\n",
      "epoch:  63, loss: 0.03575126826763153\n",
      "epoch:  64, loss: 0.0357162207365036\n",
      "epoch:  65, loss: 0.03568471968173981\n",
      "epoch:  66, loss: 0.035656385123729706\n",
      "epoch:  67, loss: 0.035630885511636734\n",
      "epoch:  68, loss: 0.035607922822237015\n",
      "epoch:  69, loss: 0.03558723255991936\n",
      "epoch:  70, loss: 0.03556856885552406\n",
      "epoch:  71, loss: 0.03555172681808472\n",
      "epoch:  72, loss: 0.0355365090072155\n",
      "epoch:  73, loss: 0.03552274405956268\n",
      "epoch:  74, loss: 0.035510286688804626\n",
      "epoch:  75, loss: 0.03549899160861969\n",
      "epoch:  76, loss: 0.035488735884428024\n",
      "epoch:  77, loss: 0.035479411482810974\n",
      "epoch:  78, loss: 0.03547092527151108\n",
      "epoch:  79, loss: 0.03546319156885147\n",
      "epoch:  80, loss: 0.03545612469315529\n",
      "epoch:  81, loss: 0.03544964641332626\n",
      "epoch:  82, loss: 0.035443708300590515\n",
      "epoch:  83, loss: 0.03543824329972267\n",
      "epoch:  84, loss: 0.03543320670723915\n",
      "epoch:  85, loss: 0.035428546369075775\n",
      "epoch:  86, loss: 0.035424236208200455\n",
      "epoch:  87, loss: 0.03542022407054901\n",
      "epoch:  88, loss: 0.035416487604379654\n",
      "epoch:  89, loss: 0.035412997007369995\n",
      "epoch:  90, loss: 0.03540971875190735\n",
      "epoch:  91, loss: 0.03540663793683052\n",
      "epoch:  92, loss: 0.03540372848510742\n",
      "epoch:  93, loss: 0.03540097549557686\n",
      "epoch:  94, loss: 0.03539836034178734\n",
      "epoch:  95, loss: 0.035395871847867966\n",
      "epoch:  96, loss: 0.03539349138736725\n",
      "epoch:  97, loss: 0.03539121523499489\n",
      "epoch:  98, loss: 0.035389017313718796\n",
      "epoch:  99, loss: 0.03538690507411957\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.SGD(model.parameters(), lr=2e-2)\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step()\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().cpu().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = -3232.1519949179137\n",
      "Test metrics:  R2 = -2950.4635092701596\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.1731976866722107\n",
      "epoch:  1, loss: 0.12661141157150269\n",
      "epoch:  2, loss: 0.09270784258842468\n",
      "epoch:  3, loss: 0.06961290538311005\n",
      "epoch:  4, loss: 0.05111697316169739\n",
      "epoch:  5, loss: 0.038837119936943054\n",
      "epoch:  6, loss: 0.035239897668361664\n",
      "epoch:  7, loss: 0.041287388652563095\n",
      "epoch:  8, loss: 0.04841260984539986\n",
      "epoch:  9, loss: 0.04987475275993347\n",
      "epoch:  10, loss: 0.046801935881376266\n",
      "epoch:  11, loss: 0.042317334562540054\n",
      "epoch:  12, loss: 0.0384860523045063\n",
      "epoch:  13, loss: 0.03611890971660614\n",
      "epoch:  14, loss: 0.035180795937776566\n",
      "epoch:  15, loss: 0.03522069752216339\n",
      "epoch:  16, loss: 0.03570188954472542\n",
      "epoch:  17, loss: 0.03618163242936134\n",
      "epoch:  18, loss: 0.03639134764671326\n",
      "epoch:  19, loss: 0.03620212897658348\n",
      "epoch:  20, loss: 0.03565441444516182\n",
      "epoch:  21, loss: 0.034885093569755554\n",
      "epoch:  22, loss: 0.03408835083246231\n",
      "epoch:  23, loss: 0.033459145575761795\n",
      "epoch:  24, loss: 0.03313704952597618\n",
      "epoch:  25, loss: 0.033159054815769196\n",
      "epoch:  26, loss: 0.03335399925708771\n",
      "epoch:  27, loss: 0.033409055322408676\n",
      "epoch:  28, loss: 0.03311245143413544\n",
      "epoch:  29, loss: 0.03251859173178673\n",
      "epoch:  30, loss: 0.03184167295694351\n",
      "epoch:  31, loss: 0.031265392899513245\n",
      "epoch:  32, loss: 0.03084847703576088\n",
      "epoch:  33, loss: 0.030522841960191727\n",
      "epoch:  34, loss: 0.03016573376953602\n",
      "epoch:  35, loss: 0.029668627306818962\n",
      "epoch:  36, loss: 0.02898463048040867\n",
      "epoch:  37, loss: 0.028140967711806297\n",
      "epoch:  38, loss: 0.027231350541114807\n",
      "epoch:  39, loss: 0.026360105723142624\n",
      "epoch:  40, loss: 0.025547506287693977\n",
      "epoch:  41, loss: 0.024678831920027733\n",
      "epoch:  42, loss: 0.023596931248903275\n",
      "epoch:  43, loss: 0.022280599921941757\n",
      "epoch:  44, loss: 0.02091130241751671\n",
      "epoch:  45, loss: 0.019721586257219315\n",
      "epoch:  46, loss: 0.018670840188860893\n",
      "epoch:  47, loss: 0.01748189702630043\n",
      "epoch:  48, loss: 0.01624392345547676\n",
      "epoch:  49, loss: 0.015339004807174206\n",
      "epoch:  50, loss: 0.014735972508788109\n",
      "epoch:  51, loss: 0.014001380652189255\n",
      "epoch:  52, loss: 0.013456922024488449\n",
      "epoch:  53, loss: 0.013215883634984493\n",
      "epoch:  54, loss: 0.012786917388439178\n",
      "epoch:  55, loss: 0.012458030134439468\n",
      "epoch:  56, loss: 0.012212828733026981\n",
      "epoch:  57, loss: 0.011692959815263748\n",
      "epoch:  58, loss: 0.011330450884997845\n",
      "epoch:  59, loss: 0.010884922929108143\n",
      "epoch:  60, loss: 0.010372109711170197\n",
      "epoch:  61, loss: 0.010049324482679367\n",
      "epoch:  62, loss: 0.009631694294512272\n",
      "epoch:  63, loss: 0.009353947825729847\n",
      "epoch:  64, loss: 0.009217716753482819\n",
      "epoch:  65, loss: 0.009078172035515308\n",
      "epoch:  66, loss: 0.009014595299959183\n",
      "epoch:  67, loss: 0.008922307752072811\n",
      "epoch:  68, loss: 0.00884947832673788\n",
      "epoch:  69, loss: 0.008737805299460888\n",
      "epoch:  70, loss: 0.008641787804663181\n",
      "epoch:  71, loss: 0.008548658341169357\n",
      "epoch:  72, loss: 0.008515618741512299\n",
      "epoch:  73, loss: 0.008475867100059986\n",
      "epoch:  74, loss: 0.008456203155219555\n",
      "epoch:  75, loss: 0.008401873521506786\n",
      "epoch:  76, loss: 0.008340672589838505\n",
      "epoch:  77, loss: 0.00827762857079506\n",
      "epoch:  78, loss: 0.008223723620176315\n",
      "epoch:  79, loss: 0.008190604858100414\n",
      "epoch:  80, loss: 0.008157015778124332\n",
      "epoch:  81, loss: 0.00813570898026228\n",
      "epoch:  82, loss: 0.00809522531926632\n",
      "epoch:  83, loss: 0.008066810667514801\n",
      "epoch:  84, loss: 0.008025923743844032\n",
      "epoch:  85, loss: 0.008002016693353653\n",
      "epoch:  86, loss: 0.007990214973688126\n",
      "epoch:  87, loss: 0.007975632324814796\n",
      "epoch:  88, loss: 0.007957425899803638\n",
      "epoch:  89, loss: 0.00792697723954916\n",
      "epoch:  90, loss: 0.007908742874860764\n",
      "epoch:  91, loss: 0.007894386537373066\n",
      "epoch:  92, loss: 0.007879977114498615\n",
      "epoch:  93, loss: 0.007861996069550514\n",
      "epoch:  94, loss: 0.007836720906198025\n",
      "epoch:  95, loss: 0.00781167671084404\n",
      "epoch:  96, loss: 0.007789398543536663\n",
      "epoch:  97, loss: 0.007772946264594793\n",
      "epoch:  98, loss: 0.007754140999168158\n",
      "epoch:  99, loss: 0.007725719828158617\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step()\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().cpu().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.7200987036630031\n",
      "Test metrics:  R2 = 0.6411664841464888\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
