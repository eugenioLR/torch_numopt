{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.8597864508628845\n",
      "epoch:  1, loss: 0.8477258086204529\n",
      "epoch:  2, loss: 0.8356391787528992\n",
      "epoch:  3, loss: 0.8235473036766052\n",
      "epoch:  4, loss: 0.8113228678703308\n",
      "epoch:  5, loss: 0.7990875840187073\n",
      "epoch:  6, loss: 0.7870096564292908\n",
      "epoch:  7, loss: 0.774722695350647\n",
      "epoch:  8, loss: 0.7623293995857239\n",
      "epoch:  9, loss: 0.7502098083496094\n",
      "epoch:  10, loss: 0.7378368973731995\n",
      "epoch:  11, loss: 0.7255964875221252\n",
      "epoch:  12, loss: 0.7133665680885315\n",
      "epoch:  13, loss: 0.7011454701423645\n",
      "epoch:  14, loss: 0.6889944672584534\n",
      "epoch:  15, loss: 0.6768544912338257\n",
      "epoch:  16, loss: 0.6647244095802307\n",
      "epoch:  17, loss: 0.6526210904121399\n",
      "epoch:  18, loss: 0.6405007839202881\n",
      "epoch:  19, loss: 0.6283899545669556\n",
      "epoch:  20, loss: 0.6163042783737183\n",
      "epoch:  21, loss: 0.6042287945747375\n",
      "epoch:  22, loss: 0.5921487808227539\n",
      "epoch:  23, loss: 0.5800405740737915\n",
      "epoch:  24, loss: 0.5678957104682922\n",
      "epoch:  25, loss: 0.5557845830917358\n",
      "epoch:  26, loss: 0.5436632633209229\n",
      "epoch:  27, loss: 0.5315689444541931\n",
      "epoch:  28, loss: 0.5194661617279053\n",
      "epoch:  29, loss: 0.5074092149734497\n",
      "epoch:  30, loss: 0.4953162670135498\n",
      "epoch:  31, loss: 0.4832773506641388\n",
      "epoch:  32, loss: 0.47118455171585083\n",
      "epoch:  33, loss: 0.4591211974620819\n",
      "epoch:  34, loss: 0.4471001923084259\n",
      "epoch:  35, loss: 0.4351315200328827\n",
      "epoch:  36, loss: 0.42317119240760803\n",
      "epoch:  37, loss: 0.4112866222858429\n",
      "epoch:  38, loss: 0.39945709705352783\n",
      "epoch:  39, loss: 0.38766801357269287\n",
      "epoch:  40, loss: 0.37604576349258423\n",
      "epoch:  41, loss: 0.36454224586486816\n",
      "epoch:  42, loss: 0.35320088267326355\n",
      "epoch:  43, loss: 0.3419560492038727\n",
      "epoch:  44, loss: 0.33071571588516235\n",
      "epoch:  45, loss: 0.31983256340026855\n",
      "epoch:  46, loss: 0.30892232060432434\n",
      "epoch:  47, loss: 0.2982248365879059\n",
      "epoch:  48, loss: 0.28769969940185547\n",
      "epoch:  49, loss: 0.27736836671829224\n",
      "epoch:  50, loss: 0.2672463357448578\n",
      "epoch:  51, loss: 0.25731757283210754\n",
      "epoch:  52, loss: 0.24762213230133057\n",
      "epoch:  53, loss: 0.2381560504436493\n",
      "epoch:  54, loss: 0.22888638079166412\n",
      "epoch:  55, loss: 0.21986626088619232\n",
      "epoch:  56, loss: 0.21104757487773895\n",
      "epoch:  57, loss: 0.20231078565120697\n",
      "epoch:  58, loss: 0.19363553822040558\n",
      "epoch:  59, loss: 0.18505434691905975\n",
      "epoch:  60, loss: 0.17673128843307495\n",
      "epoch:  61, loss: 0.1685526818037033\n",
      "epoch:  62, loss: 0.16051322221755981\n",
      "epoch:  63, loss: 0.15270528197288513\n",
      "epoch:  64, loss: 0.14517714083194733\n",
      "epoch:  65, loss: 0.137776181101799\n",
      "epoch:  66, loss: 0.13071630895137787\n",
      "epoch:  67, loss: 0.12394101917743683\n",
      "epoch:  68, loss: 0.11759526282548904\n",
      "epoch:  69, loss: 0.11139342933893204\n",
      "epoch:  70, loss: 0.10548734664916992\n",
      "epoch:  71, loss: 0.09977832436561584\n",
      "epoch:  72, loss: 0.09432084858417511\n",
      "epoch:  73, loss: 0.0890156477689743\n",
      "epoch:  74, loss: 0.08391135185956955\n",
      "epoch:  75, loss: 0.07896432280540466\n",
      "epoch:  76, loss: 0.07420387864112854\n",
      "epoch:  77, loss: 0.06960728019475937\n",
      "epoch:  78, loss: 0.06524253636598587\n",
      "epoch:  79, loss: 0.06095714494585991\n",
      "epoch:  80, loss: 0.05697987973690033\n",
      "epoch:  81, loss: 0.0531795471906662\n",
      "epoch:  82, loss: 0.04952806606888771\n",
      "epoch:  83, loss: 0.04610082134604454\n",
      "epoch:  84, loss: 0.04290980473160744\n",
      "epoch:  85, loss: 0.03989751636981964\n",
      "epoch:  86, loss: 0.0370466522872448\n",
      "epoch:  87, loss: 0.03438807278871536\n",
      "epoch:  88, loss: 0.03184721991419792\n",
      "epoch:  89, loss: 0.029493428766727448\n",
      "epoch:  90, loss: 0.02725350856781006\n",
      "epoch:  91, loss: 0.025160323828458786\n",
      "epoch:  92, loss: 0.02313484624028206\n",
      "epoch:  93, loss: 0.021290838718414307\n",
      "epoch:  94, loss: 0.019547170028090477\n",
      "epoch:  95, loss: 0.017891451716423035\n",
      "epoch:  96, loss: 0.016357650980353355\n",
      "epoch:  97, loss: 0.014833641238510609\n",
      "epoch:  98, loss: 0.013505911454558372\n",
      "epoch:  99, loss: 0.012316577136516571\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    fletcher=False,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.5249851094276587\n",
      "Test metrics:  R2 = 0.46036979706887293\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.41629379987716675\n",
      "epoch:  1, loss: 0.4052070677280426\n",
      "epoch:  2, loss: 0.39482197165489197\n",
      "epoch:  3, loss: 0.3839706480503082\n",
      "epoch:  4, loss: 0.37446022033691406\n",
      "epoch:  5, loss: 0.36243927478790283\n",
      "epoch:  6, loss: 0.34906670451164246\n",
      "epoch:  7, loss: 0.3396247923374176\n",
      "epoch:  8, loss: 0.32781982421875\n",
      "epoch:  9, loss: 0.3156156837940216\n",
      "epoch:  10, loss: 0.30398938059806824\n",
      "epoch:  11, loss: 0.29261329770088196\n",
      "epoch:  12, loss: 0.281185507774353\n",
      "epoch:  13, loss: 0.2699193060398102\n",
      "epoch:  14, loss: 0.2587921917438507\n",
      "epoch:  15, loss: 0.2477739453315735\n",
      "epoch:  16, loss: 0.23698997497558594\n",
      "epoch:  17, loss: 0.22624558210372925\n",
      "epoch:  18, loss: 0.21583344042301178\n",
      "epoch:  19, loss: 0.20580720901489258\n",
      "epoch:  20, loss: 0.19489896297454834\n",
      "epoch:  21, loss: 0.18509525060653687\n",
      "epoch:  22, loss: 0.17524056136608124\n",
      "epoch:  23, loss: 0.16535481810569763\n",
      "epoch:  24, loss: 0.15594395995140076\n",
      "epoch:  25, loss: 0.14653056859970093\n",
      "epoch:  26, loss: 0.13774581253528595\n",
      "epoch:  27, loss: 0.12930463254451752\n",
      "epoch:  28, loss: 0.12122678011655807\n",
      "epoch:  29, loss: 0.11344142258167267\n",
      "epoch:  30, loss: 0.112734355032444\n",
      "epoch:  31, loss: 0.10534269362688065\n",
      "epoch:  32, loss: 0.09835969656705856\n",
      "epoch:  33, loss: 0.09162351489067078\n",
      "epoch:  34, loss: 0.08521423488855362\n",
      "epoch:  35, loss: 0.07916243374347687\n",
      "epoch:  36, loss: 0.07334631681442261\n",
      "epoch:  37, loss: 0.06791585683822632\n",
      "epoch:  38, loss: 0.06418374180793762\n",
      "epoch:  39, loss: 0.05898761749267578\n",
      "epoch:  40, loss: 0.05429917946457863\n",
      "epoch:  41, loss: 0.04991641640663147\n",
      "epoch:  42, loss: 0.04574884846806526\n",
      "epoch:  43, loss: 0.041794467717409134\n",
      "epoch:  44, loss: 0.038116756826639175\n",
      "epoch:  45, loss: 0.03463263064622879\n",
      "epoch:  46, loss: 0.031467504799366\n",
      "epoch:  47, loss: 0.028472071513533592\n",
      "epoch:  48, loss: 0.02569178119301796\n",
      "epoch:  49, loss: 0.023070596158504486\n",
      "epoch:  50, loss: 0.020650088787078857\n",
      "epoch:  51, loss: 0.01842642016708851\n",
      "epoch:  52, loss: 0.016445452347397804\n",
      "epoch:  53, loss: 0.014655735343694687\n",
      "epoch:  54, loss: 0.013071651570498943\n",
      "epoch:  55, loss: 0.011689718812704086\n",
      "epoch:  56, loss: 0.010556667111814022\n",
      "epoch:  57, loss: 0.009496687911450863\n",
      "epoch:  58, loss: 0.008602646179497242\n",
      "epoch:  59, loss: 0.007935789413750172\n",
      "epoch:  60, loss: 0.007311380468308926\n",
      "epoch:  61, loss: 0.006794819608330727\n",
      "epoch:  62, loss: 0.006333192810416222\n",
      "epoch:  63, loss: 0.005930834449827671\n",
      "epoch:  64, loss: 0.005608190782368183\n",
      "epoch:  65, loss: 0.005320325028151274\n",
      "epoch:  66, loss: 0.005081591196358204\n",
      "epoch:  67, loss: 0.00504210963845253\n",
      "epoch:  68, loss: 0.0047707934863865376\n",
      "epoch:  69, loss: 0.004613867495208979\n",
      "epoch:  70, loss: 0.004355151206254959\n",
      "epoch:  71, loss: 0.004165389109402895\n",
      "epoch:  72, loss: 0.003931970801204443\n",
      "epoch:  73, loss: 0.0037831005174666643\n",
      "epoch:  74, loss: 0.003571651643142104\n",
      "epoch:  75, loss: 0.003264377359300852\n",
      "epoch:  76, loss: 0.0030379656236618757\n",
      "epoch:  77, loss: 0.002877927618101239\n",
      "epoch:  78, loss: 0.002764542354270816\n",
      "epoch:  79, loss: 0.0026649499777704477\n",
      "epoch:  80, loss: 0.0024880769196897745\n",
      "epoch:  81, loss: 0.0023764511570334435\n",
      "epoch:  82, loss: 0.002307442482560873\n",
      "epoch:  83, loss: 0.0022788913920521736\n",
      "epoch:  84, loss: 0.0021268620621412992\n",
      "epoch:  85, loss: 0.002043001586571336\n",
      "epoch:  86, loss: 0.001990201184526086\n",
      "epoch:  87, loss: 0.0019492963328957558\n",
      "epoch:  88, loss: 0.0018219392513856292\n",
      "epoch:  89, loss: 0.0017507408047094941\n",
      "epoch:  90, loss: 0.0017016938654705882\n",
      "epoch:  91, loss: 0.0016359922010451555\n",
      "epoch:  92, loss: 0.001554408110678196\n",
      "epoch:  93, loss: 0.0015050927177071571\n",
      "epoch:  94, loss: 0.0014692868571728468\n",
      "epoch:  95, loss: 0.0014639305882155895\n",
      "epoch:  96, loss: 0.0013948380947113037\n",
      "epoch:  97, loss: 0.0013446103548631072\n",
      "epoch:  98, loss: 0.0013082885416224599\n",
      "epoch:  99, loss: 0.001209002686664462\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    fletcher=True,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    "    solver=\"pinv\"\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9658597944912553\n",
      "Test metrics:  R2 = 0.8913674994798716\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_numopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
