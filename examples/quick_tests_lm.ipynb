{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_soom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y = True, scaled=False)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "\n",
    "torch_data = TensorDataset(torch.Tensor(X).to(device), torch.Tensor(y).to(device))\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.3770187497138977\n",
      "epoch:  1, loss: 0.07343915104866028\n",
      "epoch:  2, loss: 0.060816552489995956\n",
      "epoch:  3, loss: 0.0594768263399601\n",
      "epoch:  4, loss: 0.04071584343910217\n",
      "epoch:  5, loss: 0.031700097024440765\n",
      "epoch:  6, loss: 0.03027387335896492\n",
      "epoch:  7, loss: 0.028054429218173027\n",
      "epoch:  8, loss: 0.02784362994134426\n",
      "epoch:  9, loss: 0.027836067602038383\n",
      "epoch:  10, loss: 0.02730955369770527\n",
      "epoch:  11, loss: 0.027073441073298454\n",
      "epoch:  12, loss: 0.02700047940015793\n",
      "epoch:  13, loss: 0.026772085577249527\n",
      "epoch:  14, loss: 0.02671966329216957\n",
      "epoch:  15, loss: 0.02671007812023163\n",
      "epoch:  16, loss: 0.02654813788831234\n",
      "epoch:  17, loss: 0.02653021365404129\n",
      "epoch:  18, loss: 0.026529084891080856\n",
      "epoch:  19, loss: 0.026215026155114174\n",
      "epoch:  20, loss: 0.02615160308778286\n",
      "epoch:  21, loss: 0.02608029916882515\n",
      "epoch:  22, loss: 0.02601245604455471\n",
      "epoch:  23, loss: 0.02595224417746067\n",
      "epoch:  24, loss: 0.025913314893841743\n",
      "epoch:  25, loss: 0.025851812213659286\n",
      "epoch:  26, loss: 0.025815481320023537\n",
      "epoch:  27, loss: 0.025795692577958107\n",
      "epoch:  28, loss: 0.025788020342588425\n",
      "epoch:  29, loss: 0.025765202939510345\n",
      "epoch:  30, loss: 0.025747820734977722\n",
      "epoch:  31, loss: 0.02574113756418228\n",
      "epoch:  32, loss: 0.025736644864082336\n",
      "epoch:  33, loss: 0.025719555094838142\n",
      "epoch:  34, loss: 0.0257122740149498\n",
      "epoch:  35, loss: 0.025704290717840195\n",
      "epoch:  36, loss: 0.025699693709611893\n",
      "epoch:  37, loss: 0.025677356868982315\n",
      "epoch:  38, loss: 0.02566985785961151\n",
      "epoch:  39, loss: 0.025660185143351555\n",
      "epoch:  40, loss: 0.025653904303908348\n",
      "epoch:  41, loss: 0.025652458891272545\n",
      "epoch:  42, loss: 0.02564592845737934\n",
      "epoch:  43, loss: 0.02563929185271263\n",
      "epoch:  44, loss: 0.025638582184910774\n",
      "epoch:  45, loss: 0.025637704879045486\n",
      "epoch:  46, loss: 0.025637052953243256\n",
      "epoch:  47, loss: 0.025635920464992523\n",
      "epoch:  48, loss: 0.025635063648223877\n",
      "epoch:  49, loss: 0.025634359568357468\n",
      "epoch:  50, loss: 0.02563408762216568\n",
      "epoch:  51, loss: 0.025632917881011963\n",
      "epoch:  52, loss: 0.025631658732891083\n",
      "epoch:  53, loss: 0.025631295517086983\n",
      "epoch:  54, loss: 0.02563115768134594\n",
      "epoch:  55, loss: 0.025628894567489624\n",
      "epoch:  56, loss: 0.02562817558646202\n",
      "epoch:  57, loss: 0.02562727779150009\n",
      "epoch:  58, loss: 0.025627166032791138\n",
      "epoch:  59, loss: 0.02562577649950981\n",
      "epoch:  60, loss: 0.02562575601041317\n",
      "epoch:  61, loss: 0.025624966248869896\n",
      "epoch:  62, loss: 0.025624919682741165\n",
      "epoch:  63, loss: 0.025624863803386688\n",
      "epoch:  64, loss: 0.025624848902225494\n",
      "epoch:  65, loss: 0.025624141097068787\n",
      "epoch:  66, loss: 0.025624029338359833\n",
      "epoch:  67, loss: 0.025623571127653122\n",
      "epoch:  68, loss: 0.025623565539717674\n",
      "epoch:  69, loss: 0.025623545050621033\n",
      "epoch:  70, loss: 0.025623522698879242\n",
      "epoch:  71, loss: 0.0256235022097826\n",
      "epoch:  72, loss: 0.02562343329191208\n",
      "epoch:  73, loss: 0.025623364374041557\n",
      "epoch:  74, loss: 0.025623304769396782\n",
      "epoch:  75, loss: 0.025623267516493797\n",
      "epoch:  76, loss: 0.0256232637912035\n",
      "epoch:  77, loss: 0.025623241439461708\n",
      "epoch:  78, loss: 0.025623230263590813\n",
      "epoch:  79, loss: 0.025623217225074768\n",
      "epoch:  80, loss: 0.02562321536242962\n",
      "epoch:  81, loss: 0.025623207911849022\n",
      "epoch:  82, loss: 0.02562318928539753\n",
      "epoch:  83, loss: 0.025623183697462082\n",
      "epoch:  84, loss: 0.025623183697462082\n",
      "epoch:  85, loss: 0.025623183697462082\n",
      "epoch:  86, loss: 0.025623183697462082\n",
      "epoch:  87, loss: 0.025623183697462082\n",
      "epoch:  88, loss: 0.025623183697462082\n",
      "epoch:  89, loss: 0.025623183697462082\n",
      "epoch:  90, loss: 0.025623183697462082\n",
      "epoch:  91, loss: 0.025623183697462082\n",
      "epoch:  92, loss: 0.025623183697462082\n",
      "epoch:  93, loss: 0.025623183697462082\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size = X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = pytorch_soom.LM(model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=True, hessian_approx=False, c1=1e-4, tau=0.5, line_search_method='backtrack')\n",
    "\n",
    "all_loss = []\n",
    "patience = 0\n",
    "max_patience = 10\n",
    "for epoch in range(100):\n",
    "    print('epoch: ', epoch, end='')\n",
    "    all_loss.append(0)\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "        # opt.update(loss)\n",
    "\n",
    "        all_loss[epoch] += loss\n",
    "    \n",
    "    all_loss[epoch] /= len(data_loader)\n",
    "\n",
    "    if epoch > 0 and all_loss[epoch-1] <= all_loss[epoch]:\n",
    "        patience -= 1\n",
    "    else:\n",
    "        patience = max_patience\n",
    "        \n",
    "\n",
    "    print(', loss: {}'.format(all_loss[epoch].detach().cpu().numpy().item()))\n",
    "\n",
    "    if patience <= 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.1409468799829483\n",
      "epoch:  1, loss: 0.12833218276500702\n",
      "epoch:  2, loss: 0.12513069808483124\n",
      "epoch:  3, loss: 0.12357795238494873\n",
      "epoch:  4, loss: 0.12207825481891632\n",
      "epoch:  5, loss: 0.12062596529722214\n",
      "epoch:  6, loss: 0.11782469600439072\n",
      "epoch:  7, loss: 0.11645546555519104\n",
      "epoch:  8, loss: 0.11512772738933563\n",
      "epoch:  9, loss: 0.11260152608156204\n",
      "epoch:  10, loss: 0.11009863764047623\n",
      "epoch:  11, loss: 0.10767234861850739\n",
      "epoch:  12, loss: 0.10652058571577072\n",
      "epoch:  13, loss: 0.10438939183950424\n",
      "epoch:  14, loss: 0.10236299782991409\n",
      "epoch:  15, loss: 0.10049460083246231\n",
      "epoch:  16, loss: 0.09701022505760193\n",
      "epoch:  17, loss: 0.09013498574495316\n",
      "epoch:  18, loss: 0.07604096084833145\n",
      "epoch:  19, loss: 0.07247930765151978\n",
      "epoch:  20, loss: 0.06897406280040741\n",
      "epoch:  21, loss: 0.06559523940086365\n",
      "epoch:  22, loss: 0.06395187973976135\n",
      "epoch:  23, loss: 0.06237947940826416\n",
      "epoch:  24, loss: 0.0616178885102272\n",
      "epoch:  25, loss: 0.06088113412261009\n",
      "epoch:  26, loss: 0.060172416269779205\n",
      "epoch:  27, loss: 0.05949544161558151\n",
      "epoch:  28, loss: 0.058855243027210236\n",
      "epoch:  29, loss: 0.05854763090610504\n",
      "epoch:  30, loss: 0.05825130641460419\n",
      "epoch:  31, loss: 0.057966023683547974\n",
      "epoch:  32, loss: 0.057692062109708786\n",
      "epoch:  33, loss: 0.057432882487773895\n",
      "epoch:  34, loss: 0.057192228734493256\n",
      "epoch:  35, loss: 0.05707844719290733\n",
      "epoch:  36, loss: 0.056969884783029556\n",
      "epoch:  37, loss: 0.05686727538704872\n",
      "epoch:  38, loss: 0.05677111819386482\n",
      "epoch:  39, loss: 0.05668244883418083\n",
      "epoch:  40, loss: 0.05660077929496765\n",
      "epoch:  41, loss: 0.05652713403105736\n",
      "epoch:  42, loss: 0.056493788957595825\n",
      "epoch:  43, loss: 0.056462619453668594\n",
      "epoch:  44, loss: 0.05643359199166298\n",
      "epoch:  45, loss: 0.056406695395708084\n",
      "epoch:  46, loss: 0.056381937116384506\n",
      "epoch:  47, loss: 0.05635927990078926\n",
      "epoch:  48, loss: 0.05633861944079399\n",
      "epoch:  49, loss: 0.0563199520111084\n",
      "epoch:  50, loss: 0.056303150951862335\n",
      "epoch:  51, loss: 0.05628819018602371\n",
      "epoch:  52, loss: 0.05627492815256119\n",
      "epoch:  53, loss: 0.05626312643289566\n",
      "epoch:  54, loss: 0.05625272914767265\n",
      "epoch:  55, loss: 0.05624356493353844\n",
      "epoch:  56, loss: 0.056235384196043015\n",
      "epoch:  57, loss: 0.056227993220090866\n",
      "epoch:  58, loss: 0.056221362203359604\n",
      "epoch:  59, loss: 0.05621535703539848\n",
      "epoch:  60, loss: 0.05620986968278885\n",
      "epoch:  61, loss: 0.05620015412569046\n",
      "epoch:  62, loss: 0.056191641837358475\n",
      "epoch:  63, loss: 0.056184012442827225\n",
      "epoch:  64, loss: 0.05617022514343262\n",
      "epoch:  65, loss: 0.056120458990335464\n",
      "epoch:  66, loss: 0.05590049549937248\n",
      "epoch:  67, loss: 0.05589316040277481\n",
      "epoch:  68, loss: 0.05588054284453392\n",
      "epoch:  69, loss: 0.05585857480764389\n",
      "epoch:  70, loss: 0.055839311331510544\n",
      "epoch:  71, loss: 0.05580376088619232\n",
      "epoch:  72, loss: 0.055743489414453506\n",
      "epoch:  73, loss: 0.051414791494607925\n",
      "epoch:  74, loss: 0.051382191479206085\n",
      "epoch:  75, loss: 0.051353126764297485\n",
      "epoch:  76, loss: 0.05132719501852989\n",
      "epoch:  77, loss: 0.051303934305906296\n",
      "epoch:  78, loss: 0.051282960921525955\n",
      "epoch:  79, loss: 0.0512639619410038\n",
      "epoch:  80, loss: 0.0512298122048378\n",
      "epoch:  81, loss: 0.0512000247836113\n",
      "epoch:  82, loss: 0.05114656314253807\n",
      "epoch:  83, loss: 0.05095645785331726\n",
      "epoch:  84, loss: 0.05085912346839905\n",
      "epoch:  85, loss: 0.04437262937426567\n",
      "epoch:  86, loss: 0.044348761439323425\n",
      "epoch:  87, loss: 0.044327009469270706\n",
      "epoch:  88, loss: 0.04430720955133438\n",
      "epoch:  89, loss: 0.044289182871580124\n",
      "epoch:  90, loss: 0.044272713363170624\n",
      "epoch:  91, loss: 0.044257622212171555\n",
      "epoch:  92, loss: 0.04423049837350845\n",
      "epoch:  93, loss: 0.044207166880369186\n",
      "epoch:  94, loss: 0.04418647661805153\n",
      "epoch:  95, loss: 0.04414975643157959\n",
      "epoch:  96, loss: 0.044085852801799774\n",
      "epoch:  97, loss: 0.04315913841128349\n",
      "epoch:  98, loss: 0.04313499853014946\n",
      "epoch:  99, loss: 0.0431140661239624\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size = X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = pytorch_soom.LM(model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=False, hessian_approx=True, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "\n",
    "all_loss = []\n",
    "patience = 0\n",
    "max_patience = 10\n",
    "for epoch in range(100):\n",
    "    print('epoch: ', epoch, end='')\n",
    "    all_loss.append(0)\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "        # opt.update(loss)\n",
    "\n",
    "        all_loss[epoch] += loss\n",
    "    \n",
    "    all_loss[epoch] /= len(data_loader)\n",
    "\n",
    "    if epoch > 0 and all_loss[epoch-1] <= all_loss[epoch]:\n",
    "        patience -= 1\n",
    "    else:\n",
    "        patience = max_patience\n",
    "        \n",
    "\n",
    "    print(', loss: {}'.format(all_loss[epoch].detach().cpu().numpy().item()))\n",
    "\n",
    "    if patience <= 0:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
