{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.23260359466075897\n",
      "epoch:  1, loss: 0.221965029835701\n",
      "epoch:  2, loss: 0.209963858127594\n",
      "epoch:  3, loss: 0.1990734487771988\n",
      "epoch:  4, loss: 0.1880834698677063\n",
      "epoch:  5, loss: 0.1771688312292099\n",
      "epoch:  6, loss: 0.16675463318824768\n",
      "epoch:  7, loss: 0.15662221610546112\n",
      "epoch:  8, loss: 0.14690271019935608\n",
      "epoch:  9, loss: 0.13737857341766357\n",
      "epoch:  10, loss: 0.12793904542922974\n",
      "epoch:  11, loss: 0.11903827637434006\n",
      "epoch:  12, loss: 0.11037054657936096\n",
      "epoch:  13, loss: 0.10204827040433884\n",
      "epoch:  14, loss: 0.09419912099838257\n",
      "epoch:  15, loss: 0.08677364140748978\n",
      "epoch:  16, loss: 0.07980840653181076\n",
      "epoch:  17, loss: 0.0731511190533638\n",
      "epoch:  18, loss: 0.06682869791984558\n",
      "epoch:  19, loss: 0.061048708856105804\n",
      "epoch:  20, loss: 0.055387355387210846\n",
      "epoch:  21, loss: 0.0498712919652462\n",
      "epoch:  22, loss: 0.044560838490724564\n",
      "epoch:  23, loss: 0.039670366793870926\n",
      "epoch:  24, loss: 0.035880133509635925\n",
      "epoch:  25, loss: 0.031691666692495346\n",
      "epoch:  26, loss: 0.02771822363138199\n",
      "epoch:  27, loss: 0.02425968647003174\n",
      "epoch:  28, loss: 0.02117064781486988\n",
      "epoch:  29, loss: 0.01857217401266098\n",
      "epoch:  30, loss: 0.01627851277589798\n",
      "epoch:  31, loss: 0.014505486935377121\n",
      "epoch:  32, loss: 0.012722766026854515\n",
      "epoch:  33, loss: 0.011164414696395397\n",
      "epoch:  34, loss: 0.00992642156779766\n",
      "epoch:  35, loss: 0.00881232600659132\n",
      "epoch:  36, loss: 0.007850594818592072\n",
      "epoch:  37, loss: 0.007022500038146973\n",
      "epoch:  38, loss: 0.00629738625138998\n",
      "epoch:  39, loss: 0.005646293982863426\n",
      "epoch:  40, loss: 0.005016655195504427\n",
      "epoch:  41, loss: 0.004439322277903557\n",
      "epoch:  42, loss: 0.003902978030964732\n",
      "epoch:  43, loss: 0.003450799034908414\n",
      "epoch:  44, loss: 0.0033422603737562895\n",
      "epoch:  45, loss: 0.003121756948530674\n",
      "epoch:  46, loss: 0.002927052089944482\n",
      "epoch:  47, loss: 0.0027866626624017954\n",
      "epoch:  48, loss: 0.00278627872467041\n",
      "epoch:  49, loss: 0.002523182425647974\n",
      "epoch:  50, loss: 0.002332210773602128\n",
      "epoch:  51, loss: 0.002201349474489689\n",
      "epoch:  52, loss: 0.002114227507263422\n",
      "epoch:  53, loss: 0.0019366974011063576\n",
      "epoch:  54, loss: 0.0017658801516517997\n",
      "epoch:  55, loss: 0.0016621985705569386\n",
      "epoch:  56, loss: 0.0015971289249137044\n",
      "epoch:  57, loss: 0.0014389526331797242\n",
      "epoch:  58, loss: 0.001307769911363721\n",
      "epoch:  59, loss: 0.0012335204519331455\n",
      "epoch:  60, loss: 0.0011871379101648927\n",
      "epoch:  61, loss: 0.0010424426291137934\n",
      "epoch:  62, loss: 0.0009469698998145759\n",
      "epoch:  63, loss: 0.0008889927994459867\n",
      "epoch:  64, loss: 0.0008488643215969205\n",
      "epoch:  65, loss: 0.0008173197275027633\n",
      "epoch:  66, loss: 0.0006647881236858666\n",
      "epoch:  67, loss: 0.0005932293133810163\n",
      "epoch:  68, loss: 0.0005637615686282516\n",
      "epoch:  69, loss: 0.0005409856676124036\n",
      "epoch:  70, loss: 0.0005074925138615072\n",
      "epoch:  71, loss: 0.00040463879122398794\n",
      "epoch:  72, loss: 0.0003818381519522518\n",
      "epoch:  73, loss: 0.0003674871113616973\n",
      "epoch:  74, loss: 0.00035733275581151247\n",
      "epoch:  75, loss: 0.00034982780925929546\n",
      "epoch:  76, loss: 0.0003453891258686781\n",
      "epoch:  77, loss: 0.0003437792765907943\n",
      "epoch:  78, loss: 0.00034262280678376555\n",
      "epoch:  79, loss: 0.0003286566643510014\n",
      "epoch:  80, loss: 0.0003191737923771143\n",
      "epoch:  81, loss: 0.00031292159110307693\n",
      "epoch:  82, loss: 0.0003116670995950699\n",
      "epoch:  83, loss: 0.0003046135534532368\n",
      "epoch:  84, loss: 0.0003000414289999753\n",
      "epoch:  85, loss: 0.00029869325226172805\n",
      "epoch:  86, loss: 0.0002927614259533584\n",
      "epoch:  87, loss: 0.00028900321922264993\n",
      "epoch:  88, loss: 0.0002885742287617177\n",
      "epoch:  89, loss: 0.00028302136342972517\n",
      "epoch:  90, loss: 0.0002795459295157343\n",
      "epoch:  91, loss: 0.0002790387661661953\n",
      "epoch:  92, loss: 0.00027382635744288564\n",
      "epoch:  93, loss: 0.00027065869653597474\n",
      "epoch:  94, loss: 0.0002686678199097514\n",
      "epoch:  95, loss: 0.00026582766440697014\n",
      "epoch:  96, loss: 0.00026266410714015365\n",
      "epoch:  97, loss: 0.00026240680017508566\n",
      "epoch:  98, loss: 0.0002572430530562997\n",
      "epoch:  99, loss: 0.0002541931753512472\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=False, c1=1e-4, tau=0.1, line_search_method=\"backtrack\"\n",
    ")\n",
    "\n",
    "times = []\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9923825777638684\n",
      "Test metrics:  R2 = 0.9898356439706428\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.3783176839351654\n",
      "epoch:  1, loss: 0.3652935028076172\n",
      "epoch:  2, loss: 0.35275277495384216\n",
      "epoch:  3, loss: 0.34015265107154846\n",
      "epoch:  4, loss: 0.32716795802116394\n",
      "epoch:  5, loss: 0.3146699070930481\n",
      "epoch:  6, loss: 0.30243203043937683\n",
      "epoch:  7, loss: 0.2916263937950134\n",
      "epoch:  8, loss: 0.28288137912750244\n",
      "epoch:  9, loss: 0.2710270285606384\n",
      "epoch:  10, loss: 0.2591533362865448\n",
      "epoch:  11, loss: 0.24715657532215118\n",
      "epoch:  12, loss: 0.23590722680091858\n",
      "epoch:  13, loss: 0.22505290806293488\n",
      "epoch:  14, loss: 0.2145189791917801\n",
      "epoch:  15, loss: 0.2040371298789978\n",
      "epoch:  16, loss: 0.19370156526565552\n",
      "epoch:  17, loss: 0.1838294416666031\n",
      "epoch:  18, loss: 0.17416192591190338\n",
      "epoch:  19, loss: 0.164704367518425\n",
      "epoch:  20, loss: 0.15559229254722595\n",
      "epoch:  21, loss: 0.14657019078731537\n",
      "epoch:  22, loss: 0.13779735565185547\n",
      "epoch:  23, loss: 0.12949351966381073\n",
      "epoch:  24, loss: 0.12140266597270966\n",
      "epoch:  25, loss: 0.11335846781730652\n",
      "epoch:  26, loss: 0.10829580575227737\n",
      "epoch:  27, loss: 0.10127469897270203\n",
      "epoch:  28, loss: 0.094524085521698\n",
      "epoch:  29, loss: 0.0880390852689743\n",
      "epoch:  30, loss: 0.08183727413415909\n",
      "epoch:  31, loss: 0.07579077035188675\n",
      "epoch:  32, loss: 0.07043476402759552\n",
      "epoch:  33, loss: 0.0653781145811081\n",
      "epoch:  34, loss: 0.060357820242643356\n",
      "epoch:  35, loss: 0.059887226670980453\n",
      "epoch:  36, loss: 0.05618206411600113\n",
      "epoch:  37, loss: 0.051931705325841904\n",
      "epoch:  38, loss: 0.04787526652216911\n",
      "epoch:  39, loss: 0.044131480157375336\n",
      "epoch:  40, loss: 0.040723152458667755\n",
      "epoch:  41, loss: 0.03767259791493416\n",
      "epoch:  42, loss: 0.034713443368673325\n",
      "epoch:  43, loss: 0.03210346773266792\n",
      "epoch:  44, loss: 0.029499845579266548\n",
      "epoch:  45, loss: 0.0276175569742918\n",
      "epoch:  46, loss: 0.025533784180879593\n",
      "epoch:  47, loss: 0.023771943524479866\n",
      "epoch:  48, loss: 0.02189870923757553\n",
      "epoch:  49, loss: 0.020325414836406708\n",
      "epoch:  50, loss: 0.018833842128515244\n",
      "epoch:  51, loss: 0.017478449270129204\n",
      "epoch:  52, loss: 0.01637086272239685\n",
      "epoch:  53, loss: 0.015514813363552094\n",
      "epoch:  54, loss: 0.014782934449613094\n",
      "epoch:  55, loss: 0.014367337338626385\n",
      "epoch:  56, loss: 0.013380506075918674\n",
      "epoch:  57, loss: 0.013023086823523045\n",
      "epoch:  58, loss: 0.012501545250415802\n",
      "epoch:  59, loss: 0.01165192574262619\n",
      "epoch:  60, loss: 0.011182519607245922\n",
      "epoch:  61, loss: 0.010670807212591171\n",
      "epoch:  62, loss: 0.010110689327120781\n",
      "epoch:  63, loss: 0.009416076354682446\n",
      "epoch:  64, loss: 0.009120111353695393\n",
      "epoch:  65, loss: 0.008590771816670895\n",
      "epoch:  66, loss: 0.008021226152777672\n",
      "epoch:  67, loss: 0.00781933218240738\n",
      "epoch:  68, loss: 0.0072197807021439075\n",
      "epoch:  69, loss: 0.006504882592707872\n",
      "epoch:  70, loss: 0.006364581640809774\n",
      "epoch:  71, loss: 0.006286212243139744\n",
      "epoch:  72, loss: 0.006215316243469715\n",
      "epoch:  73, loss: 0.006150532979518175\n",
      "epoch:  74, loss: 0.006087903864681721\n",
      "epoch:  75, loss: 0.0056235711090266705\n",
      "epoch:  76, loss: 0.005579318851232529\n",
      "epoch:  77, loss: 0.005471752490848303\n",
      "epoch:  78, loss: 0.005185629706829786\n",
      "epoch:  79, loss: 0.005111356265842915\n",
      "epoch:  80, loss: 0.0048868292942643166\n",
      "epoch:  81, loss: 0.004640716128051281\n",
      "epoch:  82, loss: 0.004594992380589247\n",
      "epoch:  83, loss: 0.004536615218967199\n",
      "epoch:  84, loss: 0.00433576013892889\n",
      "epoch:  85, loss: 0.004085731692612171\n",
      "epoch:  86, loss: 0.004052259959280491\n",
      "epoch:  87, loss: 0.0039183408953249454\n",
      "epoch:  88, loss: 0.0038265157490968704\n",
      "epoch:  89, loss: 0.00375489704310894\n",
      "epoch:  90, loss: 0.003671141341328621\n",
      "epoch:  91, loss: 0.0035558303352445364\n",
      "epoch:  92, loss: 0.003471625503152609\n",
      "epoch:  93, loss: 0.0034105456434190273\n",
      "epoch:  94, loss: 0.00336274947039783\n",
      "epoch:  95, loss: 0.0032669357024133205\n",
      "epoch:  96, loss: 0.003196990117430687\n",
      "epoch:  97, loss: 0.0031649554148316383\n",
      "epoch:  98, loss: 0.0030060529243201017\n",
      "epoch:  99, loss: 0.0030000132974237204\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=True, c1=1e-4, tau=0.1, line_search_method=\"backtrack\"\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9026239282826991\n",
      "Test metrics:  R2 = 0.4435574699525612\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
