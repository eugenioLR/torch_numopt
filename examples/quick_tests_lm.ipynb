{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.6041828989982605\n",
      "epoch:  1, loss: 0.5923678278923035\n",
      "epoch:  2, loss: 0.579876184463501\n",
      "epoch:  3, loss: 0.5664399862289429\n",
      "epoch:  4, loss: 0.5530651211738586\n",
      "epoch:  5, loss: 0.539283812046051\n",
      "epoch:  6, loss: 0.5261838436126709\n",
      "epoch:  7, loss: 0.5131703615188599\n",
      "epoch:  8, loss: 0.5005210041999817\n",
      "epoch:  9, loss: 0.48811075091362\n",
      "epoch:  10, loss: 0.4758986234664917\n",
      "epoch:  11, loss: 0.4639546573162079\n",
      "epoch:  12, loss: 0.45220747590065\n",
      "epoch:  13, loss: 0.44046881794929504\n",
      "epoch:  14, loss: 0.42881065607070923\n",
      "epoch:  15, loss: 0.4170415699481964\n",
      "epoch:  16, loss: 0.405215322971344\n",
      "epoch:  17, loss: 0.39366331696510315\n",
      "epoch:  18, loss: 0.3820994198322296\n",
      "epoch:  19, loss: 0.3706481158733368\n",
      "epoch:  20, loss: 0.35917308926582336\n",
      "epoch:  21, loss: 0.34778541326522827\n",
      "epoch:  22, loss: 0.33641815185546875\n",
      "epoch:  23, loss: 0.32515227794647217\n",
      "epoch:  24, loss: 0.3139820098876953\n",
      "epoch:  25, loss: 0.30283302068710327\n",
      "epoch:  26, loss: 0.29192450642585754\n",
      "epoch:  27, loss: 0.2812080681324005\n",
      "epoch:  28, loss: 0.2710534930229187\n",
      "epoch:  29, loss: 0.26016682386398315\n",
      "epoch:  30, loss: 0.24969390034675598\n",
      "epoch:  31, loss: 0.239424929022789\n",
      "epoch:  32, loss: 0.22922754287719727\n",
      "epoch:  33, loss: 0.2193395346403122\n",
      "epoch:  34, loss: 0.20961788296699524\n",
      "epoch:  35, loss: 0.20011207461357117\n",
      "epoch:  36, loss: 0.19084949791431427\n",
      "epoch:  37, loss: 0.18206866085529327\n",
      "epoch:  38, loss: 0.173147052526474\n",
      "epoch:  39, loss: 0.16470801830291748\n",
      "epoch:  40, loss: 0.15663082897663116\n",
      "epoch:  41, loss: 0.14875467121601105\n",
      "epoch:  42, loss: 0.14106430113315582\n",
      "epoch:  43, loss: 0.1334678828716278\n",
      "epoch:  44, loss: 0.12969885766506195\n",
      "epoch:  45, loss: 0.12222254276275635\n",
      "epoch:  46, loss: 0.11482185870409012\n",
      "epoch:  47, loss: 0.10745486617088318\n",
      "epoch:  48, loss: 0.10004886239767075\n",
      "epoch:  49, loss: 0.09306028485298157\n",
      "epoch:  50, loss: 0.08626343309879303\n",
      "epoch:  51, loss: 0.07997425645589828\n",
      "epoch:  52, loss: 0.07401135563850403\n",
      "epoch:  53, loss: 0.06846286356449127\n",
      "epoch:  54, loss: 0.06312422454357147\n",
      "epoch:  55, loss: 0.05805288627743721\n",
      "epoch:  56, loss: 0.05327381566166878\n",
      "epoch:  57, loss: 0.04896331578493118\n",
      "epoch:  58, loss: 0.04496888443827629\n",
      "epoch:  59, loss: 0.04152907431125641\n",
      "epoch:  60, loss: 0.03838345408439636\n",
      "epoch:  61, loss: 0.035564448684453964\n",
      "epoch:  62, loss: 0.0331013947725296\n",
      "epoch:  63, loss: 0.03060927987098694\n",
      "epoch:  64, loss: 0.027967065572738647\n",
      "epoch:  65, loss: 0.02533249370753765\n",
      "epoch:  66, loss: 0.02297656424343586\n",
      "epoch:  67, loss: 0.02131248451769352\n",
      "epoch:  68, loss: 0.019238807260990143\n",
      "epoch:  69, loss: 0.017416391521692276\n",
      "epoch:  70, loss: 0.01573227345943451\n",
      "epoch:  71, loss: 0.014222454279661179\n",
      "epoch:  72, loss: 0.012832190841436386\n",
      "epoch:  73, loss: 0.011573869735002518\n",
      "epoch:  74, loss: 0.010428627952933311\n",
      "epoch:  75, loss: 0.009431948885321617\n",
      "epoch:  76, loss: 0.008556741289794445\n",
      "epoch:  77, loss: 0.007779729086905718\n",
      "epoch:  78, loss: 0.007071250583976507\n",
      "epoch:  79, loss: 0.006469141226261854\n",
      "epoch:  80, loss: 0.005941041745245457\n",
      "epoch:  81, loss: 0.005472960416227579\n",
      "epoch:  82, loss: 0.005053524859249592\n",
      "epoch:  83, loss: 0.004691645503044128\n",
      "epoch:  84, loss: 0.004416643176227808\n",
      "epoch:  85, loss: 0.004166239406913519\n",
      "epoch:  86, loss: 0.00396997993811965\n",
      "epoch:  87, loss: 0.003793064272031188\n",
      "epoch:  88, loss: 0.003647980047389865\n",
      "epoch:  89, loss: 0.0036009130999445915\n",
      "epoch:  90, loss: 0.003511837450787425\n",
      "epoch:  91, loss: 0.0034455489367246628\n",
      "epoch:  92, loss: 0.0034023397602140903\n",
      "epoch:  93, loss: 0.0033481454011052847\n",
      "epoch:  94, loss: 0.003271213499829173\n",
      "epoch:  95, loss: 0.0032258813735097647\n",
      "epoch:  96, loss: 0.0031972250435501337\n",
      "epoch:  97, loss: 0.00313077331520617\n",
      "epoch:  98, loss: 0.0030764436814934015\n",
      "epoch:  99, loss: 0.003044285112991929\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    use_diagonal=False,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "times = []\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9106782134763903\n",
      "Test metrics:  R2 = 0.8359498994285598\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eugeniolr/Documents/invAI/torch_numopt/src/torch_numopt/utils.py:33: UserWarning: torch.linalg.svd: During SVD computation with the selected cusolver driver, batches 0 failed to converge. A more accurate method will be used to compute the SVD as a fallback. Check doc at https://pytorch.org/docs/stable/generated/torch.linalg.svd.html (Triggered internally at /pytorch/aten/src/ATen/native/cuda/linalg/BatchLinearAlgebraLib.cpp:690.)\n",
      "  U, S, Vt = torch.linalg.svd(mat)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ", loss: 0.574187695980072\n",
      "epoch:  1, loss: 0.5595420002937317\n",
      "epoch:  2, loss: 0.5473747253417969\n",
      "epoch:  3, loss: 0.5358685255050659\n",
      "epoch:  4, loss: 0.5241893529891968\n",
      "epoch:  5, loss: 0.512570858001709\n",
      "epoch:  6, loss: 0.5007033944129944\n",
      "epoch:  7, loss: 0.4930351972579956\n",
      "epoch:  8, loss: 0.48082101345062256\n",
      "epoch:  9, loss: 0.4689486622810364\n",
      "epoch:  10, loss: 0.4572763741016388\n",
      "epoch:  11, loss: 0.4460606276988983\n",
      "epoch:  12, loss: 0.43414872884750366\n",
      "epoch:  13, loss: 0.4217337667942047\n",
      "epoch:  14, loss: 0.40962451696395874\n",
      "epoch:  15, loss: 0.3973752558231354\n",
      "epoch:  16, loss: 0.38541772961616516\n",
      "epoch:  17, loss: 0.3735707700252533\n",
      "epoch:  18, loss: 0.3621201515197754\n",
      "epoch:  19, loss: 0.35035744309425354\n",
      "epoch:  20, loss: 0.33871990442276\n",
      "epoch:  21, loss: 0.3267153799533844\n",
      "epoch:  22, loss: 0.3150375187397003\n",
      "epoch:  23, loss: 0.30425792932510376\n",
      "epoch:  24, loss: 0.29316675662994385\n",
      "epoch:  25, loss: 0.28234684467315674\n",
      "epoch:  26, loss: 0.27173101902008057\n",
      "epoch:  27, loss: 0.2608616054058075\n",
      "epoch:  28, loss: 0.25133517384529114\n",
      "epoch:  29, loss: 0.24112242460250854\n",
      "epoch:  30, loss: 0.23112252354621887\n",
      "epoch:  31, loss: 0.2212652564048767\n",
      "epoch:  32, loss: 0.21144087612628937\n",
      "epoch:  33, loss: 0.20185771584510803\n",
      "epoch:  34, loss: 0.19246041774749756\n",
      "epoch:  35, loss: 0.183399960398674\n",
      "epoch:  36, loss: 0.17460955679416656\n",
      "epoch:  37, loss: 0.16588455438613892\n",
      "epoch:  38, loss: 0.15742574632167816\n",
      "epoch:  39, loss: 0.14944776892662048\n",
      "epoch:  40, loss: 0.14124970138072968\n",
      "epoch:  41, loss: 0.13328541815280914\n",
      "epoch:  42, loss: 0.12570787966251373\n",
      "epoch:  43, loss: 0.11842731386423111\n",
      "epoch:  44, loss: 0.1113070473074913\n",
      "epoch:  45, loss: 0.10450302064418793\n",
      "epoch:  46, loss: 0.0979151800274849\n",
      "epoch:  47, loss: 0.09153369814157486\n",
      "epoch:  48, loss: 0.0855194479227066\n",
      "epoch:  49, loss: 0.07967730611562729\n",
      "epoch:  50, loss: 0.07421229779720306\n",
      "epoch:  51, loss: 0.069040946662426\n",
      "epoch:  52, loss: 0.06410949677228928\n",
      "epoch:  53, loss: 0.059421002864837646\n",
      "epoch:  54, loss: 0.054947175085544586\n",
      "epoch:  55, loss: 0.05072502791881561\n",
      "epoch:  56, loss: 0.046706657856702805\n",
      "epoch:  57, loss: 0.04300100356340408\n",
      "epoch:  58, loss: 0.03938370198011398\n",
      "epoch:  59, loss: 0.03606130927801132\n",
      "epoch:  60, loss: 0.0330212265253067\n",
      "epoch:  61, loss: 0.03022899106144905\n",
      "epoch:  62, loss: 0.02763042412698269\n",
      "epoch:  63, loss: 0.025241537019610405\n",
      "epoch:  64, loss: 0.02306048385798931\n",
      "epoch:  65, loss: 0.020917516201734543\n",
      "epoch:  66, loss: 0.019205113872885704\n",
      "epoch:  67, loss: 0.017546938732266426\n",
      "epoch:  68, loss: 0.01615312695503235\n",
      "epoch:  69, loss: 0.014750120230019093\n",
      "epoch:  70, loss: 0.013475128449499607\n",
      "epoch:  71, loss: 0.012271341867744923\n",
      "epoch:  72, loss: 0.01125739049166441\n",
      "epoch:  73, loss: 0.010333671234548092\n",
      "epoch:  74, loss: 0.009537451900541782\n",
      "epoch:  75, loss: 0.008455650880932808\n",
      "epoch:  76, loss: 0.007920646108686924\n",
      "epoch:  77, loss: 0.007149199023842812\n",
      "epoch:  78, loss: 0.006684732157737017\n",
      "epoch:  79, loss: 0.006274526007473469\n",
      "epoch:  80, loss: 0.005841956008225679\n",
      "epoch:  81, loss: 0.005316196475178003\n",
      "epoch:  82, loss: 0.0050515830516815186\n",
      "epoch:  83, loss: 0.004764184355735779\n",
      "epoch:  84, loss: 0.004532758612185717\n",
      "epoch:  85, loss: 0.004358907695859671\n",
      "epoch:  86, loss: 0.004184451419860125\n",
      "epoch:  87, loss: 0.004138628952205181\n",
      "epoch:  88, loss: 0.003830991918221116\n",
      "epoch:  89, loss: 0.0035922604147344828\n",
      "epoch:  90, loss: 0.0035670518409460783\n",
      "epoch:  91, loss: 0.0033564800396561623\n",
      "epoch:  92, loss: 0.003349380334839225\n",
      "epoch:  93, loss: 0.0033324407413601875\n",
      "epoch:  94, loss: 0.0031024913769215345\n",
      "epoch:  95, loss: 0.003012531902641058\n",
      "epoch:  96, loss: 0.002947963774204254\n",
      "epoch:  97, loss: 0.0029460459481924772\n",
      "epoch:  98, loss: 0.0028419403824955225\n",
      "epoch:  99, loss: 0.002773965010419488\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    use_diagonal=True,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9199096787710449\n",
      "Test metrics:  R2 = 0.8542646221726717\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_numopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
