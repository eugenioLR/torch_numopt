{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.06667272746562958\n",
      "epoch:  1, loss: 0.060904838144779205\n",
      "epoch:  2, loss: 0.055892251431941986\n",
      "epoch:  3, loss: 0.05172598361968994\n",
      "epoch:  4, loss: 0.047193098813295364\n",
      "epoch:  5, loss: 0.042146582156419754\n",
      "epoch:  6, loss: 0.03771459311246872\n",
      "epoch:  7, loss: 0.033440738916397095\n",
      "epoch:  8, loss: 0.029551977291703224\n",
      "epoch:  9, loss: 0.026136722415685654\n",
      "epoch:  10, loss: 0.02308354154229164\n",
      "epoch:  11, loss: 0.020622970536351204\n",
      "epoch:  12, loss: 0.018363410606980324\n",
      "epoch:  13, loss: 0.016537850722670555\n",
      "epoch:  14, loss: 0.014877413399517536\n",
      "epoch:  15, loss: 0.013560688123106956\n",
      "epoch:  16, loss: 0.01230364665389061\n",
      "epoch:  17, loss: 0.01119944453239441\n",
      "epoch:  18, loss: 0.010232573375105858\n",
      "epoch:  19, loss: 0.009532867930829525\n",
      "epoch:  20, loss: 0.008966640569269657\n",
      "epoch:  21, loss: 0.008453687652945518\n",
      "epoch:  22, loss: 0.008056050166487694\n",
      "epoch:  23, loss: 0.007768329232931137\n",
      "epoch:  24, loss: 0.007491347845643759\n",
      "epoch:  25, loss: 0.007256527431309223\n",
      "epoch:  26, loss: 0.0070450096391141415\n",
      "epoch:  27, loss: 0.006842051167041063\n",
      "epoch:  28, loss: 0.0066471099853515625\n",
      "epoch:  29, loss: 0.006520288530737162\n",
      "epoch:  30, loss: 0.006371477153152227\n",
      "epoch:  31, loss: 0.0062284874729812145\n",
      "epoch:  32, loss: 0.006083409767597914\n",
      "epoch:  33, loss: 0.005913866683840752\n",
      "epoch:  34, loss: 0.005790544208139181\n",
      "epoch:  35, loss: 0.0057370602153241634\n",
      "epoch:  36, loss: 0.005600442178547382\n",
      "epoch:  37, loss: 0.005441893357783556\n",
      "epoch:  38, loss: 0.005308331456035376\n",
      "epoch:  39, loss: 0.005217726808041334\n",
      "epoch:  40, loss: 0.0050738537684082985\n",
      "epoch:  41, loss: 0.004946290049701929\n",
      "epoch:  42, loss: 0.004820642061531544\n",
      "epoch:  43, loss: 0.00471035810187459\n",
      "epoch:  44, loss: 0.004617294296622276\n",
      "epoch:  45, loss: 0.00451279291883111\n",
      "epoch:  46, loss: 0.0044179330579936504\n",
      "epoch:  47, loss: 0.004318580962717533\n",
      "epoch:  48, loss: 0.00427227420732379\n",
      "epoch:  49, loss: 0.004251720383763313\n",
      "epoch:  50, loss: 0.004234916530549526\n",
      "epoch:  51, loss: 0.004075303673744202\n",
      "epoch:  52, loss: 0.003978914115577936\n",
      "epoch:  53, loss: 0.0038810744881629944\n",
      "epoch:  54, loss: 0.003815882606431842\n",
      "epoch:  55, loss: 0.003775833873078227\n",
      "epoch:  56, loss: 0.0036967499181628227\n",
      "epoch:  57, loss: 0.0036486650351434946\n",
      "epoch:  58, loss: 0.0035633209627121687\n",
      "epoch:  59, loss: 0.0035069617442786694\n",
      "epoch:  60, loss: 0.0034693556372076273\n",
      "epoch:  61, loss: 0.003445777576416731\n",
      "epoch:  62, loss: 0.0033797966316342354\n",
      "epoch:  63, loss: 0.003336612368002534\n",
      "epoch:  64, loss: 0.0033356028143316507\n",
      "epoch:  65, loss: 0.0032492107711732388\n",
      "epoch:  66, loss: 0.003199928440153599\n",
      "epoch:  67, loss: 0.0031691952608525753\n",
      "epoch:  68, loss: 0.0031330252531915903\n",
      "epoch:  69, loss: 0.0030706918332725763\n",
      "epoch:  70, loss: 0.003034445457160473\n",
      "epoch:  71, loss: 0.003011303022503853\n",
      "epoch:  72, loss: 0.0029535198118537664\n",
      "epoch:  73, loss: 0.0029096873477101326\n",
      "epoch:  74, loss: 0.002884779591113329\n",
      "epoch:  75, loss: 0.002864859765395522\n",
      "epoch:  76, loss: 0.002809383673593402\n",
      "epoch:  77, loss: 0.0027808677405118942\n",
      "epoch:  78, loss: 0.0027639607433229685\n",
      "epoch:  79, loss: 0.002739205025136471\n",
      "epoch:  80, loss: 0.0026976331137120724\n",
      "epoch:  81, loss: 0.0026749807875603437\n",
      "epoch:  82, loss: 0.002654621610417962\n",
      "epoch:  83, loss: 0.0026135570369660854\n",
      "epoch:  84, loss: 0.002591175027191639\n",
      "epoch:  85, loss: 0.0025763625744730234\n",
      "epoch:  86, loss: 0.002530801808461547\n",
      "epoch:  87, loss: 0.0025034279096871614\n",
      "epoch:  88, loss: 0.0024877970572561026\n",
      "epoch:  89, loss: 0.002462812466546893\n",
      "epoch:  90, loss: 0.0024320511147379875\n",
      "epoch:  91, loss: 0.002414756454527378\n",
      "epoch:  92, loss: 0.0024028527550399303\n",
      "epoch:  93, loss: 0.002392868511378765\n",
      "epoch:  94, loss: 0.0023834933526813984\n",
      "epoch:  95, loss: 0.0023793638683855534\n",
      "epoch:  96, loss: 0.002350542228668928\n",
      "epoch:  97, loss: 0.0023301781620830297\n",
      "epoch:  98, loss: 0.0023178907576948404\n",
      "epoch:  99, loss: 0.00231191492639482\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=False, c1=1e-4, tau=0.1, line_search_method=\"backtrack\"\n",
    ")\n",
    "\n",
    "times = []\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9247288903203285\n",
      "Test metrics:  R2 = 0.8826490323424914\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.33193057775497437\n",
      "epoch:  1, loss: 0.3225981891155243\n",
      "epoch:  2, loss: 0.3110601603984833\n",
      "epoch:  3, loss: 0.29986247420310974\n",
      "epoch:  4, loss: 0.28774046897888184\n",
      "epoch:  5, loss: 0.28667518496513367\n",
      "epoch:  6, loss: 0.2768465280532837\n",
      "epoch:  7, loss: 0.25803226232528687\n",
      "epoch:  8, loss: 0.2483709752559662\n",
      "epoch:  9, loss: 0.23762786388397217\n",
      "epoch:  10, loss: 0.22619642317295074\n",
      "epoch:  11, loss: 0.21426819264888763\n",
      "epoch:  12, loss: 0.20327989757061005\n",
      "epoch:  13, loss: 0.19252778589725494\n",
      "epoch:  14, loss: 0.18175937235355377\n",
      "epoch:  15, loss: 0.1711900383234024\n",
      "epoch:  16, loss: 0.16081362962722778\n",
      "epoch:  17, loss: 0.15149827301502228\n",
      "epoch:  18, loss: 0.14149236679077148\n",
      "epoch:  19, loss: 0.13192133605480194\n",
      "epoch:  20, loss: 0.12253682315349579\n",
      "epoch:  21, loss: 0.11362215876579285\n",
      "epoch:  22, loss: 0.10550106316804886\n",
      "epoch:  23, loss: 0.09726785868406296\n",
      "epoch:  24, loss: 0.09023772925138474\n",
      "epoch:  25, loss: 0.08311010152101517\n",
      "epoch:  26, loss: 0.07671460509300232\n",
      "epoch:  27, loss: 0.07018467783927917\n",
      "epoch:  28, loss: 0.06416887044906616\n",
      "epoch:  29, loss: 0.05841570347547531\n",
      "epoch:  30, loss: 0.053164396435022354\n",
      "epoch:  31, loss: 0.04822394996881485\n",
      "epoch:  32, loss: 0.043383415788412094\n",
      "epoch:  33, loss: 0.03906380757689476\n",
      "epoch:  34, loss: 0.03502398356795311\n",
      "epoch:  35, loss: 0.03129066154360771\n",
      "epoch:  36, loss: 0.027844643220305443\n",
      "epoch:  37, loss: 0.024710942059755325\n",
      "epoch:  38, loss: 0.021827176213264465\n",
      "epoch:  39, loss: 0.01910613477230072\n",
      "epoch:  40, loss: 0.01670454815030098\n",
      "epoch:  41, loss: 0.014485717751085758\n",
      "epoch:  42, loss: 0.012426912784576416\n",
      "epoch:  43, loss: 0.010568841360509396\n",
      "epoch:  44, loss: 0.008991480804979801\n",
      "epoch:  45, loss: 0.007682188879698515\n",
      "epoch:  46, loss: 0.006524969823658466\n",
      "epoch:  47, loss: 0.0055727045983076096\n",
      "epoch:  48, loss: 0.004746457561850548\n",
      "epoch:  49, loss: 0.00414805393666029\n",
      "epoch:  50, loss: 0.003553639864549041\n",
      "epoch:  51, loss: 0.0031198004726320505\n",
      "epoch:  52, loss: 0.0026882642414420843\n",
      "epoch:  53, loss: 0.0026098412927240133\n",
      "epoch:  54, loss: 0.0024243632797151804\n",
      "epoch:  55, loss: 0.00229701679199934\n",
      "epoch:  56, loss: 0.0022071106359362602\n",
      "epoch:  57, loss: 0.0020776167511940002\n",
      "epoch:  58, loss: 0.001929706777445972\n",
      "epoch:  59, loss: 0.0018353338818997145\n",
      "epoch:  60, loss: 0.0017730470281094313\n",
      "epoch:  61, loss: 0.0016664877766743302\n",
      "epoch:  62, loss: 0.001551310415379703\n",
      "epoch:  63, loss: 0.0014833605382591486\n",
      "epoch:  64, loss: 0.0014484480489045382\n",
      "epoch:  65, loss: 0.0013129592407494783\n",
      "epoch:  66, loss: 0.001243214588612318\n",
      "epoch:  67, loss: 0.0011978402035310864\n",
      "epoch:  68, loss: 0.0011614823015406728\n",
      "epoch:  69, loss: 0.001101862988434732\n",
      "epoch:  70, loss: 0.001029995852150023\n",
      "epoch:  71, loss: 0.0009869864443317056\n",
      "epoch:  72, loss: 0.0009578599128872156\n",
      "epoch:  73, loss: 0.0009341558907181025\n",
      "epoch:  74, loss: 0.0009285390260629356\n",
      "epoch:  75, loss: 0.0008684605127200484\n",
      "epoch:  76, loss: 0.0008264949428848922\n",
      "epoch:  77, loss: 0.0007960000657476485\n",
      "epoch:  78, loss: 0.000790477148257196\n",
      "epoch:  79, loss: 0.0007347774226218462\n",
      "epoch:  80, loss: 0.00072005286347121\n",
      "epoch:  81, loss: 0.000639566162135452\n",
      "epoch:  82, loss: 0.0005932105705142021\n",
      "epoch:  83, loss: 0.0005621278542093933\n",
      "epoch:  84, loss: 0.0005396840278990567\n",
      "epoch:  85, loss: 0.0005234723794274032\n",
      "epoch:  86, loss: 0.0005097331013530493\n",
      "epoch:  87, loss: 0.0004993705661036074\n",
      "epoch:  88, loss: 0.0004885054077021778\n",
      "epoch:  89, loss: 0.00048141731531359255\n",
      "epoch:  90, loss: 0.000474379223305732\n",
      "epoch:  91, loss: 0.0004677348188124597\n",
      "epoch:  92, loss: 0.00046237121568992734\n",
      "epoch:  93, loss: 0.0004563058027997613\n",
      "epoch:  94, loss: 0.0004518445930443704\n",
      "epoch:  95, loss: 0.0004456813621800393\n",
      "epoch:  96, loss: 0.00044301271555013955\n",
      "epoch:  97, loss: 0.0004367494839243591\n",
      "epoch:  98, loss: 0.00043103296775370836\n",
      "epoch:  99, loss: 0.0004263086011633277\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    model.parameters(), lr=1, mu=0.001, mu_dec=0.1, model=model, use_diagonal=True, c1=1e-4, tau=0.1, line_search_method=\"backtrack\"\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9868969644175797\n",
      "Test metrics:  R2 = 0.9614377460292693\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
