{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.15185248851776123\n",
      "epoch:  1, loss: 0.14543534815311432\n",
      "epoch:  2, loss: 0.13415062427520752\n",
      "epoch:  3, loss: 0.12443262338638306\n",
      "epoch:  4, loss: 0.11456643790006638\n",
      "epoch:  5, loss: 0.10508512705564499\n",
      "epoch:  6, loss: 0.09614015370607376\n",
      "epoch:  7, loss: 0.08828138560056686\n",
      "epoch:  8, loss: 0.08242309838533401\n",
      "epoch:  9, loss: 0.07528004795312881\n",
      "epoch:  10, loss: 0.06879105418920517\n",
      "epoch:  11, loss: 0.062445588409900665\n",
      "epoch:  12, loss: 0.05618146434426308\n",
      "epoch:  13, loss: 0.04970080778002739\n",
      "epoch:  14, loss: 0.04362639784812927\n",
      "epoch:  15, loss: 0.038415614515542984\n",
      "epoch:  16, loss: 0.0338042788207531\n",
      "epoch:  17, loss: 0.029594436287879944\n",
      "epoch:  18, loss: 0.026243355125188828\n",
      "epoch:  19, loss: 0.02301601693034172\n",
      "epoch:  20, loss: 0.01996503956615925\n",
      "epoch:  21, loss: 0.01738516241312027\n",
      "epoch:  22, loss: 0.015019590966403484\n",
      "epoch:  23, loss: 0.01302588451653719\n",
      "epoch:  24, loss: 0.011534327641129494\n",
      "epoch:  25, loss: 0.010068624280393124\n",
      "epoch:  26, loss: 0.008835624903440475\n",
      "epoch:  27, loss: 0.007672588806599379\n",
      "epoch:  28, loss: 0.006700512953102589\n",
      "epoch:  29, loss: 0.005874263122677803\n",
      "epoch:  30, loss: 0.005138671025633812\n",
      "epoch:  31, loss: 0.004518017638474703\n",
      "epoch:  32, loss: 0.004028160125017166\n",
      "epoch:  33, loss: 0.00353319407440722\n",
      "epoch:  34, loss: 0.003146031405776739\n",
      "epoch:  35, loss: 0.0028428295627236366\n",
      "epoch:  36, loss: 0.0027615008875727654\n",
      "epoch:  37, loss: 0.002551819896325469\n",
      "epoch:  38, loss: 0.0024047428742051125\n",
      "epoch:  39, loss: 0.0023970170877873898\n",
      "epoch:  40, loss: 0.0021414614748209715\n",
      "epoch:  41, loss: 0.001970273442566395\n",
      "epoch:  42, loss: 0.0018676946638152003\n",
      "epoch:  43, loss: 0.0018040398135781288\n",
      "epoch:  44, loss: 0.0016080087516456842\n",
      "epoch:  45, loss: 0.0014737739693373442\n",
      "epoch:  46, loss: 0.0014028948498889804\n",
      "epoch:  47, loss: 0.0013587475987151265\n",
      "epoch:  48, loss: 0.0011627625208348036\n",
      "epoch:  49, loss: 0.0010734827956184745\n",
      "epoch:  50, loss: 0.001028254977427423\n",
      "epoch:  51, loss: 0.0008954831282608211\n",
      "epoch:  52, loss: 0.0008353233570232987\n",
      "epoch:  53, loss: 0.0007947079720906913\n",
      "epoch:  54, loss: 0.0007659316761419177\n",
      "epoch:  55, loss: 0.0006972964038141072\n",
      "epoch:  56, loss: 0.0006349548930302262\n",
      "epoch:  57, loss: 0.0006185089587233961\n",
      "epoch:  58, loss: 0.0005544653395190835\n",
      "epoch:  59, loss: 0.0005256857839412987\n",
      "epoch:  60, loss: 0.0005083282012492418\n",
      "epoch:  61, loss: 0.0004798276349902153\n",
      "epoch:  62, loss: 0.00044997717486694455\n",
      "epoch:  63, loss: 0.0004371431132312864\n",
      "epoch:  64, loss: 0.0004304918402340263\n",
      "epoch:  65, loss: 0.00042597524588927627\n",
      "epoch:  66, loss: 0.00042190123349428177\n",
      "epoch:  67, loss: 0.00041860967758111656\n",
      "epoch:  68, loss: 0.00041526180575601757\n",
      "epoch:  69, loss: 0.0004121989768464118\n",
      "epoch:  70, loss: 0.0004093715106137097\n",
      "epoch:  71, loss: 0.00040656598866917193\n",
      "epoch:  72, loss: 0.00040335429366678\n",
      "epoch:  73, loss: 0.0004001797060482204\n",
      "epoch:  74, loss: 0.00039721731445752084\n",
      "epoch:  75, loss: 0.0003943858901038766\n",
      "epoch:  76, loss: 0.0003915111592505127\n",
      "epoch:  77, loss: 0.0003885001060552895\n",
      "epoch:  78, loss: 0.0003855827380903065\n",
      "epoch:  79, loss: 0.000382911937776953\n",
      "epoch:  80, loss: 0.00038028013659641147\n",
      "epoch:  81, loss: 0.00037785019958391786\n",
      "epoch:  82, loss: 0.000375443632947281\n",
      "epoch:  83, loss: 0.00037316817906685174\n",
      "epoch:  84, loss: 0.0003706890274770558\n",
      "epoch:  85, loss: 0.0003683864197228104\n",
      "epoch:  86, loss: 0.0003666881821118295\n",
      "epoch:  87, loss: 0.0003649572900030762\n",
      "epoch:  88, loss: 0.00036282287328504026\n",
      "epoch:  89, loss: 0.0003610131097957492\n",
      "epoch:  90, loss: 0.0003587683604564518\n",
      "epoch:  91, loss: 0.00035749925882555544\n",
      "epoch:  92, loss: 0.00035543960984796286\n",
      "epoch:  93, loss: 0.0003535271098371595\n",
      "epoch:  94, loss: 0.000351845461409539\n",
      "epoch:  95, loss: 0.0003504072374198586\n",
      "epoch:  96, loss: 0.0003492404648568481\n",
      "epoch:  97, loss: 0.00034792738733813167\n",
      "epoch:  98, loss: 0.00034635269548743963\n",
      "epoch:  99, loss: 0.00034550687996670604\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    use_diagonal=False,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "times = []\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9899531341772125\n",
      "Test metrics:  R2 = 0.9809480085976271\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.2768445611000061\n",
      "epoch:  1, loss: 0.2647181749343872\n",
      "epoch:  2, loss: 0.25178372859954834\n",
      "epoch:  3, loss: 0.24008145928382874\n",
      "epoch:  4, loss: 0.22773155570030212\n",
      "epoch:  5, loss: 0.21432165801525116\n",
      "epoch:  6, loss: 0.19943107664585114\n",
      "epoch:  7, loss: 0.18868085741996765\n",
      "epoch:  8, loss: 0.17798803746700287\n",
      "epoch:  9, loss: 0.16768838465213776\n",
      "epoch:  10, loss: 0.15738897025585175\n",
      "epoch:  11, loss: 0.14823564887046814\n",
      "epoch:  12, loss: 0.1385813057422638\n",
      "epoch:  13, loss: 0.12955832481384277\n",
      "epoch:  14, loss: 0.12084385007619858\n",
      "epoch:  15, loss: 0.1124948188662529\n",
      "epoch:  16, loss: 0.10427310317754745\n",
      "epoch:  17, loss: 0.09659654647111893\n",
      "epoch:  18, loss: 0.08893730491399765\n",
      "epoch:  19, loss: 0.08171466737985611\n",
      "epoch:  20, loss: 0.07497870177030563\n",
      "epoch:  21, loss: 0.06853996217250824\n",
      "epoch:  22, loss: 0.06250086426734924\n",
      "epoch:  23, loss: 0.05687445029616356\n",
      "epoch:  24, loss: 0.05165313556790352\n",
      "epoch:  25, loss: 0.04731715843081474\n",
      "epoch:  26, loss: 0.04297832027077675\n",
      "epoch:  27, loss: 0.038733139634132385\n",
      "epoch:  28, loss: 0.03656764328479767\n",
      "epoch:  29, loss: 0.033046115189790726\n",
      "epoch:  30, loss: 0.029850805178284645\n",
      "epoch:  31, loss: 0.02683299593627453\n",
      "epoch:  32, loss: 0.02404937893152237\n",
      "epoch:  33, loss: 0.02146073989570141\n",
      "epoch:  34, loss: 0.019052734598517418\n",
      "epoch:  35, loss: 0.016990527510643005\n",
      "epoch:  36, loss: 0.015212953090667725\n",
      "epoch:  37, loss: 0.013782491907477379\n",
      "epoch:  38, loss: 0.012694043107330799\n",
      "epoch:  39, loss: 0.01141998078674078\n",
      "epoch:  40, loss: 0.010533393360674381\n",
      "epoch:  41, loss: 0.009588468819856644\n",
      "epoch:  42, loss: 0.008894684724509716\n",
      "epoch:  43, loss: 0.008044306188821793\n",
      "epoch:  44, loss: 0.007802026811987162\n",
      "epoch:  45, loss: 0.007193323224782944\n",
      "epoch:  46, loss: 0.0070459721609950066\n",
      "epoch:  47, loss: 0.006470824591815472\n",
      "epoch:  48, loss: 0.0063034784980118275\n",
      "epoch:  49, loss: 0.005878559313714504\n",
      "epoch:  50, loss: 0.005861887242645025\n",
      "epoch:  51, loss: 0.005470606032758951\n",
      "epoch:  52, loss: 0.005339375231415033\n",
      "epoch:  53, loss: 0.005136996507644653\n",
      "epoch:  54, loss: 0.005005581304430962\n",
      "epoch:  55, loss: 0.004856103099882603\n",
      "epoch:  56, loss: 0.004577984102070332\n",
      "epoch:  57, loss: 0.004240905400365591\n",
      "epoch:  58, loss: 0.003991767764091492\n",
      "epoch:  59, loss: 0.0038188593462109566\n",
      "epoch:  60, loss: 0.003697995562106371\n",
      "epoch:  61, loss: 0.00367392273619771\n",
      "epoch:  62, loss: 0.0034627215936779976\n",
      "epoch:  63, loss: 0.0033387811854481697\n",
      "epoch:  64, loss: 0.0032628485932946205\n",
      "epoch:  65, loss: 0.0031760490965098143\n",
      "epoch:  66, loss: 0.0029928218573331833\n",
      "epoch:  67, loss: 0.002903406275436282\n",
      "epoch:  68, loss: 0.0028514275327324867\n",
      "epoch:  69, loss: 0.0026776331942528486\n",
      "epoch:  70, loss: 0.0025921694468706846\n",
      "epoch:  71, loss: 0.002548306481912732\n",
      "epoch:  72, loss: 0.002420203760266304\n",
      "epoch:  73, loss: 0.002332682954147458\n",
      "epoch:  74, loss: 0.0022915005683898926\n",
      "epoch:  75, loss: 0.002241995418444276\n",
      "epoch:  76, loss: 0.002155452035367489\n",
      "epoch:  77, loss: 0.0021063603926450014\n",
      "epoch:  78, loss: 0.0020779932383447886\n",
      "epoch:  79, loss: 0.001975963357836008\n",
      "epoch:  80, loss: 0.001921866205520928\n",
      "epoch:  81, loss: 0.001886382233351469\n",
      "epoch:  82, loss: 0.0018000794807448983\n",
      "epoch:  83, loss: 0.0017329606926068664\n",
      "epoch:  84, loss: 0.0016918755136430264\n",
      "epoch:  85, loss: 0.0016486921813338995\n",
      "epoch:  86, loss: 0.0015784412389621139\n",
      "epoch:  87, loss: 0.0015339766396209598\n",
      "epoch:  88, loss: 0.0014915615320205688\n",
      "epoch:  89, loss: 0.0014070516917854548\n",
      "epoch:  90, loss: 0.0013524049427360296\n",
      "epoch:  91, loss: 0.0013146427227184176\n",
      "epoch:  92, loss: 0.0012873989762738347\n",
      "epoch:  93, loss: 0.0012216190807521343\n",
      "epoch:  94, loss: 0.0011692952830344439\n",
      "epoch:  95, loss: 0.001133354497142136\n",
      "epoch:  96, loss: 0.0011073392815887928\n",
      "epoch:  97, loss: 0.001085874973796308\n",
      "epoch:  98, loss: 0.0010683751897886395\n",
      "epoch:  99, loss: 0.0010405076900497079\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "opt = torch_numopt.LM(\n",
    "    params=model.parameters(),\n",
    "    model=model,\n",
    "    lr=1,\n",
    "    mu=0.001,\n",
    "    mu_dec=0.1,\n",
    "    use_diagonal=True,\n",
    "    c1=1e-4,\n",
    "    tau=0.1,\n",
    "    line_search_method=\"backtrack\",\n",
    "    line_search_cond=\"armijo\",\n",
    ")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9702296569429305\n",
      "Test metrics:  R2 = 0.8933314844817699\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
