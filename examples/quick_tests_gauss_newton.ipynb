{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pytorch_soom\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device='cpu'):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "X, y = load_diabetes(return_X_y = True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "print(X.shape)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "\n",
    "torch_data = TensorDataset(torch.Tensor(X).to(device), torch.Tensor(y).to(device))\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.15774840116500854\n",
      "epoch:  1, loss: 0.09400651603937149\n",
      "epoch:  2, loss: 0.09352152049541473\n",
      "epoch:  3, loss: 0.09267937391996384\n",
      "epoch:  4, loss: 0.0918719545006752\n",
      "epoch:  5, loss: 0.08763954043388367\n",
      "epoch:  6, loss: 0.08355627208948135\n",
      "epoch:  7, loss: 0.07810920476913452\n",
      "epoch:  8, loss: 0.07755916565656662\n",
      "epoch:  9, loss: 0.07141479104757309\n",
      "epoch:  10, loss: 0.06623217463493347\n",
      "epoch:  11, loss: 0.06173088029026985\n",
      "epoch:  12, loss: 0.058281317353248596\n",
      "epoch:  13, loss: 0.057781241834163666\n",
      "epoch:  14, loss: 0.05320478603243828\n",
      "epoch:  15, loss: 0.048655737191438675\n",
      "epoch:  16, loss: 0.04498245567083359\n",
      "epoch:  17, loss: 0.04306308925151825\n",
      "epoch:  18, loss: 0.041482482105493546\n",
      "epoch:  19, loss: 0.0395968072116375\n",
      "epoch:  20, loss: 0.03869064897298813\n",
      "epoch:  21, loss: 0.03836766257882118\n",
      "epoch:  22, loss: 0.037059180438518524\n",
      "epoch:  23, loss: 0.03463312238454819\n",
      "epoch:  24, loss: 0.033263444900512695\n",
      "epoch:  25, loss: 0.03297042474150658\n",
      "epoch:  26, loss: 0.03274529427289963\n",
      "epoch:  27, loss: 0.03245355188846588\n",
      "epoch:  28, loss: 0.03243590146303177\n",
      "epoch:  29, loss: 0.03172673285007477\n",
      "epoch:  30, loss: 0.030115904286503792\n",
      "epoch:  31, loss: 0.02887975238263607\n",
      "epoch:  32, loss: 0.02793944999575615\n",
      "epoch:  33, loss: 0.02777090109884739\n",
      "epoch:  34, loss: 0.027496811002492905\n",
      "epoch:  35, loss: 0.02717164345085621\n",
      "epoch:  36, loss: 0.02690735086798668\n",
      "epoch:  37, loss: 0.026692500337958336\n",
      "epoch:  38, loss: 0.02638203650712967\n",
      "epoch:  39, loss: 0.026180153712630272\n",
      "epoch:  40, loss: 0.026032786816358566\n",
      "epoch:  41, loss: 0.025832530111074448\n",
      "epoch:  42, loss: 0.024352118372917175\n",
      "epoch:  43, loss: 0.024088313803076744\n",
      "epoch:  44, loss: 0.022984547540545464\n",
      "epoch:  45, loss: 0.022710591554641724\n",
      "epoch:  46, loss: 0.021994903683662415\n",
      "epoch:  47, loss: 0.021970344707369804\n",
      "epoch:  48, loss: 0.02169840969145298\n",
      "epoch:  49, loss: 0.02085605263710022\n",
      "epoch:  50, loss: 0.020338216796517372\n",
      "epoch:  51, loss: 0.01891847513616085\n",
      "epoch:  52, loss: 0.01863519661128521\n",
      "epoch:  53, loss: 0.018385300412774086\n",
      "epoch:  54, loss: 0.01777515560388565\n",
      "epoch:  55, loss: 0.01751955971121788\n",
      "epoch:  56, loss: 0.017275139689445496\n",
      "epoch:  57, loss: 0.01708013378083706\n",
      "epoch:  58, loss: 0.016872532665729523\n",
      "epoch:  59, loss: 0.016687078401446342\n",
      "epoch:  60, loss: 0.016504768282175064\n",
      "epoch:  61, loss: 0.0163258146494627\n",
      "epoch:  62, loss: 0.01622309908270836\n",
      "epoch:  63, loss: 0.016203254461288452\n",
      "epoch:  64, loss: 0.016055384650826454\n",
      "epoch:  65, loss: 0.015905924141407013\n",
      "epoch:  66, loss: 0.01582014188170433\n",
      "epoch:  67, loss: 0.015667464584112167\n",
      "epoch:  68, loss: 0.015455871820449829\n",
      "epoch:  69, loss: 0.015386907383799553\n",
      "epoch:  70, loss: 0.015359763987362385\n",
      "epoch:  71, loss: 0.015263459645211697\n",
      "epoch:  72, loss: 0.015127993188798428\n",
      "epoch:  73, loss: 0.015014096163213253\n",
      "epoch:  74, loss: 0.01493708323687315\n",
      "epoch:  75, loss: 0.014834255911409855\n",
      "epoch:  76, loss: 0.014738108962774277\n",
      "epoch:  77, loss: 0.014646542258560658\n",
      "epoch:  78, loss: 0.014552393928170204\n",
      "epoch:  79, loss: 0.014472746290266514\n",
      "epoch:  80, loss: 0.014353304170072079\n",
      "epoch:  81, loss: 0.014335386455059052\n",
      "epoch:  82, loss: 0.014261959120631218\n",
      "epoch:  83, loss: 0.01420432049781084\n",
      "epoch:  84, loss: 0.01418109517544508\n",
      "epoch:  85, loss: 0.014112703502178192\n",
      "epoch:  86, loss: 0.014064825139939785\n",
      "epoch:  87, loss: 0.013911529444158077\n",
      "epoch:  88, loss: 0.013891801238059998\n",
      "epoch:  89, loss: 0.01381317712366581\n",
      "epoch:  90, loss: 0.013759858906269073\n",
      "epoch:  91, loss: 0.013675939291715622\n",
      "epoch:  92, loss: 0.013592970557510853\n",
      "epoch:  93, loss: 0.013475336134433746\n",
      "epoch:  94, loss: 0.013449961319565773\n",
      "epoch:  95, loss: 0.013396146707236767\n",
      "epoch:  96, loss: 0.013298182748258114\n",
      "epoch:  97, loss: 0.013201420195400715\n",
      "epoch:  98, loss: 0.013201241381466389\n",
      "epoch:  99, loss: 0.0131340641528368\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size = X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "# loss_fn = nn.L1Loss()\n",
    "# loss_fn = nn.NLLLoss(reduction='mean')\n",
    "opt = pytorch_soom.GaussNewton(model.parameters(), lr=1, model=model, c1=1e-4, tau=0.1, line_search_method='backtrack', line_search_cond='armijo')\n",
    "# opt = pytorch_soom.GaussNewton(model.parameters(), lr=1, model=model, c1=1e-4, tau=0.5, line_search_method='backtrack', line_search_cond='wolfe')\n",
    "# opt = pytorch_soom.GaussNewton(model.parameters(), lr=1, model=model, hessian_approx=False, c1=1e-4, tau=0.5, line_search_method='backtrack', line_search_cond='strong-wolfe')\n",
    "# opt = pytorch_soom.GaussNewton(model.parameters(), lr=1, model=model, hessian_approx=False, c1=1e-4, tau=0.5, line_search_method='backtrack', line_search_cond='goldstein')\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print('epoch: ', epoch, end='')\n",
    "    all_loss[epoch+1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch+1] += loss\n",
    "    all_loss[epoch+1] /= len(data_loader)\n",
    "    print(', loss: {}'.format(all_loss[epoch+1].detach().numpy().item()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
