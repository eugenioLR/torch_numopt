{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "# X, y = make_friedman1(n_samples=10, noise=1e-2)\n",
    "# X, y = make_friedman1(n_samples=100, noise=1e-2)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "# X, y = make_friedman1(n_samples=100000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.3234073221683502\n",
      "epoch:  1, loss: 0.24785415828227997\n",
      "epoch:  2, loss: 0.2046290785074234\n",
      "epoch:  3, loss: 0.15621094405651093\n",
      "epoch:  4, loss: 0.1323913037776947\n",
      "epoch:  5, loss: 0.11074137687683105\n",
      "epoch:  6, loss: 0.09178738296031952\n",
      "epoch:  7, loss: 0.07593279331922531\n",
      "epoch:  8, loss: 0.06373278051614761\n",
      "epoch:  9, loss: 0.013012963347136974\n",
      "epoch:  10, loss: 0.01233764085918665\n",
      "epoch:  11, loss: 0.008445371873676777\n",
      "epoch:  12, loss: 0.008171920664608479\n",
      "epoch:  13, loss: 0.0062322672456502914\n",
      "epoch:  14, loss: 0.005135722924023867\n",
      "epoch:  15, loss: 0.004390272311866283\n",
      "epoch:  16, loss: 0.0038077107165008783\n",
      "epoch:  17, loss: 0.0035265639889985323\n",
      "epoch:  18, loss: 0.003117428394034505\n",
      "epoch:  19, loss: 0.0028176449704915285\n",
      "epoch:  20, loss: 0.002569577656686306\n",
      "epoch:  21, loss: 0.0023751293774694204\n",
      "epoch:  22, loss: 0.0022022342309355736\n",
      "epoch:  23, loss: 0.002160147065296769\n",
      "epoch:  24, loss: 0.0019659199751913548\n",
      "epoch:  25, loss: 0.0018460084684193134\n",
      "epoch:  26, loss: 0.001758977654390037\n",
      "epoch:  27, loss: 0.0016719996929168701\n",
      "epoch:  28, loss: 0.0015946626663208008\n",
      "epoch:  29, loss: 0.0015182988718152046\n",
      "epoch:  30, loss: 0.0014547975733876228\n",
      "epoch:  31, loss: 0.0013967857230454683\n",
      "epoch:  32, loss: 0.0013456630986183882\n",
      "epoch:  33, loss: 0.0012884224997833371\n",
      "epoch:  34, loss: 0.0012869562488049269\n",
      "epoch:  35, loss: 0.00105577171780169\n",
      "epoch:  36, loss: 0.0009927577339112759\n",
      "epoch:  37, loss: 0.0009547896916046739\n",
      "epoch:  38, loss: 0.0009282386163249612\n",
      "epoch:  39, loss: 0.0009080824092961848\n",
      "epoch:  40, loss: 0.0008909853640943766\n",
      "epoch:  41, loss: 0.0008733186987228692\n",
      "epoch:  42, loss: 0.0008114592055790126\n",
      "epoch:  43, loss: 0.0007791395764797926\n",
      "epoch:  44, loss: 0.0007569168228656054\n",
      "epoch:  45, loss: 0.0007383484626188874\n",
      "epoch:  46, loss: 0.0007256569806486368\n",
      "epoch:  47, loss: 0.0007094616303220391\n",
      "epoch:  48, loss: 0.0006997648160904646\n",
      "epoch:  49, loss: 0.0006876178085803986\n",
      "epoch:  50, loss: 0.0006804974982514977\n",
      "epoch:  51, loss: 0.0006711907917633653\n",
      "epoch:  52, loss: 0.0006699421792291105\n",
      "epoch:  53, loss: 0.0006626796675845981\n",
      "epoch:  54, loss: 0.0006612951401621103\n",
      "epoch:  55, loss: 0.0006554105784744024\n",
      "epoch:  56, loss: 0.0006502473843283951\n",
      "epoch:  57, loss: 0.0006445473409257829\n",
      "epoch:  58, loss: 0.0006433703820221126\n",
      "epoch:  59, loss: 0.0006361642736010253\n",
      "epoch:  60, loss: 0.0006311399629339576\n",
      "epoch:  61, loss: 0.0006265680422075093\n",
      "epoch:  62, loss: 0.0006217757472768426\n",
      "epoch:  63, loss: 0.0006187389953993261\n",
      "epoch:  64, loss: 0.0006175984744913876\n",
      "epoch:  65, loss: 0.000612668867688626\n",
      "epoch:  66, loss: 0.0006090887472964823\n",
      "epoch:  67, loss: 0.0006049163639545441\n",
      "epoch:  68, loss: 0.0006037090206518769\n",
      "epoch:  69, loss: 0.0006006333278492093\n",
      "epoch:  70, loss: 0.0005956247332505882\n",
      "epoch:  71, loss: 0.0005931708728894591\n",
      "epoch:  72, loss: 0.0005894885980524123\n",
      "epoch:  73, loss: 0.0005855522467754781\n",
      "epoch:  74, loss: 0.0005832996685057878\n",
      "epoch:  75, loss: 0.0005808158311992884\n",
      "epoch:  76, loss: 0.0005771218566223979\n",
      "epoch:  77, loss: 0.0005751142743974924\n",
      "epoch:  78, loss: 0.0005727132665924728\n",
      "epoch:  79, loss: 0.0005702046328224242\n",
      "epoch:  80, loss: 0.0005687781958840787\n",
      "epoch:  81, loss: 0.000567356706596911\n",
      "epoch:  82, loss: 0.0005627723876386881\n",
      "epoch:  83, loss: 0.0005601756856776774\n",
      "epoch:  84, loss: 0.0005556538235396147\n",
      "epoch:  85, loss: 0.0005545862950384617\n",
      "epoch:  86, loss: 0.0005523155559785664\n",
      "epoch:  87, loss: 0.0005489602917805314\n",
      "epoch:  88, loss: 0.0005475403741002083\n",
      "epoch:  89, loss: 0.0005445511778816581\n",
      "epoch:  90, loss: 0.0005432596080936491\n",
      "epoch:  91, loss: 0.0005423254333436489\n",
      "epoch:  92, loss: 0.0005396051565185189\n",
      "epoch:  93, loss: 0.0005381939699873328\n",
      "epoch:  94, loss: 0.0005349267739802599\n",
      "epoch:  95, loss: 0.000533748185262084\n",
      "epoch:  96, loss: 0.0005306421080604196\n",
      "epoch:  97, loss: 0.0005306347738951445\n",
      "epoch:  98, loss: 0.0005306238308548927\n",
      "epoch:  99, loss: 0.0005277455784380436\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=0.01, line_search_method=\"const\")\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.1, line_search_method=\"backtrack\", line_search_cond=\"armijo\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"strong-wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"goldstein\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9862373707843252\n",
      "Test metrics:  R2 = 0.9241984476049709\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_numopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
