{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.4913996756076813\n",
      "epoch:  1, loss: 12.60409927368164\n",
      "epoch:  2, loss: 1.0642656087875366\n",
      "epoch:  3, loss: 2.261833667755127\n",
      "epoch:  4, loss: 0.15371383726596832\n",
      "epoch:  5, loss: 0.04317309334874153\n",
      "epoch:  6, loss: 0.017214877530932426\n",
      "epoch:  7, loss: 0.012059775181114674\n",
      "epoch:  8, loss: 0.008290204219520092\n",
      "epoch:  9, loss: 0.006806775461882353\n",
      "epoch:  10, loss: 0.005685069598257542\n",
      "epoch:  11, loss: 0.0049519967287778854\n",
      "epoch:  12, loss: 0.004418948199599981\n",
      "epoch:  13, loss: 0.003955833613872528\n",
      "epoch:  14, loss: 0.003595501882955432\n",
      "epoch:  15, loss: 0.0032774542924016714\n",
      "epoch:  16, loss: 0.0030173049308359623\n",
      "epoch:  17, loss: 0.002818218432366848\n",
      "epoch:  18, loss: 0.0026553079951554537\n",
      "epoch:  19, loss: 0.0025193998590111732\n",
      "epoch:  20, loss: 0.0023874593898653984\n",
      "epoch:  21, loss: 0.0022924088407307863\n",
      "epoch:  22, loss: 0.0021873945370316505\n",
      "epoch:  23, loss: 0.0021038770209997892\n",
      "epoch:  24, loss: 0.0020285965874791145\n",
      "epoch:  25, loss: 0.001965723466128111\n",
      "epoch:  26, loss: 0.0019078392069786787\n",
      "epoch:  27, loss: 0.001854107715189457\n",
      "epoch:  28, loss: 0.0017930901376530528\n",
      "epoch:  29, loss: 0.0017469218000769615\n",
      "epoch:  30, loss: 0.0017033079639077187\n",
      "epoch:  31, loss: 0.0016732512740418315\n",
      "epoch:  32, loss: 0.0016346456250175834\n",
      "epoch:  33, loss: 0.0016052061691880226\n",
      "epoch:  34, loss: 0.0015709060244262218\n",
      "epoch:  35, loss: 0.0015431658830493689\n",
      "epoch:  36, loss: 0.00150674965698272\n",
      "epoch:  37, loss: 0.001484208507463336\n",
      "epoch:  38, loss: 0.001449110102839768\n",
      "epoch:  39, loss: 0.001416006125509739\n",
      "epoch:  40, loss: 0.0013822504552081227\n",
      "epoch:  41, loss: 0.0013449586695060134\n",
      "epoch:  42, loss: 0.0013132494641467929\n",
      "epoch:  43, loss: 0.0012860232964158058\n",
      "epoch:  44, loss: 0.0012592800194397569\n",
      "epoch:  45, loss: 0.0012336447834968567\n",
      "epoch:  46, loss: 0.001209900132380426\n",
      "epoch:  47, loss: 0.0011863192776218057\n",
      "epoch:  48, loss: 0.0011650363449007273\n",
      "epoch:  49, loss: 0.001149818766862154\n",
      "epoch:  50, loss: 0.0011255488498136401\n",
      "epoch:  51, loss: 0.0011076960945501924\n",
      "epoch:  52, loss: 0.0010896450839936733\n",
      "epoch:  53, loss: 0.001073221443220973\n",
      "epoch:  54, loss: 0.0010542890522629023\n",
      "epoch:  55, loss: 0.0010357185965403914\n",
      "epoch:  56, loss: 0.001019232557155192\n",
      "epoch:  57, loss: 0.0010014979634433985\n",
      "epoch:  58, loss: 0.0009870051871985197\n",
      "epoch:  59, loss: 0.0009729160228744149\n",
      "epoch:  60, loss: 0.0009590715053491294\n",
      "epoch:  61, loss: 0.0009424821473658085\n",
      "epoch:  62, loss: 0.0009306193678639829\n",
      "epoch:  63, loss: 0.0009178575710393488\n",
      "epoch:  64, loss: 0.0009058147552423179\n",
      "epoch:  65, loss: 0.0008936204831115901\n",
      "epoch:  66, loss: 0.0008826476987451315\n",
      "epoch:  67, loss: 0.000876726524438709\n",
      "epoch:  68, loss: 0.0008662414620630443\n",
      "epoch:  69, loss: 0.0008518362883478403\n",
      "epoch:  70, loss: 0.0008405015687458217\n",
      "epoch:  71, loss: 0.000830867444165051\n",
      "epoch:  72, loss: 0.0008205480990000069\n",
      "epoch:  73, loss: 0.0008136996766552329\n",
      "epoch:  74, loss: 0.0008043480920605361\n",
      "epoch:  75, loss: 0.0007970615988597274\n",
      "epoch:  76, loss: 0.0007875148439779878\n",
      "epoch:  77, loss: 0.0007780636660754681\n",
      "epoch:  78, loss: 0.000772784580476582\n",
      "epoch:  79, loss: 0.0007679280824959278\n",
      "epoch:  80, loss: 0.0007565135601907969\n",
      "epoch:  81, loss: 0.0007473567966371775\n",
      "epoch:  82, loss: 0.0007396169821731746\n",
      "epoch:  83, loss: 0.0007323796162381768\n",
      "epoch:  84, loss: 0.0007294157985597849\n",
      "epoch:  85, loss: 0.0007193661294877529\n",
      "epoch:  86, loss: 0.0007109309080988169\n",
      "epoch:  87, loss: 0.0007040143827907741\n",
      "epoch:  88, loss: 0.0006979989120736718\n",
      "epoch:  89, loss: 0.0006931189564056695\n",
      "epoch:  90, loss: 0.0006867893971502781\n",
      "epoch:  91, loss: 0.0006816890672780573\n",
      "epoch:  92, loss: 0.0006768841412849724\n",
      "epoch:  93, loss: 0.0006735509377904236\n",
      "epoch:  94, loss: 0.0006694920593872666\n",
      "epoch:  95, loss: 0.0006643030210398138\n",
      "epoch:  96, loss: 0.0006596714956685901\n",
      "epoch:  97, loss: 0.0006566110532730818\n",
      "epoch:  98, loss: 0.0006508614169433713\n",
      "epoch:  99, loss: 0.0006467874627560377\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=0.1, line_search_method=\"const\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9804414733734099\n",
      "Test metrics:  R2 = 0.9354575704083824\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracking Line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.3968493640422821\n",
      "epoch:  1, loss: 0.340989887714386\n",
      "epoch:  2, loss: 0.26643890142440796\n",
      "epoch:  3, loss: 0.2318674474954605\n",
      "epoch:  4, loss: 0.18996557593345642\n",
      "epoch:  5, loss: 0.1554243564605713\n",
      "epoch:  6, loss: 0.06055226922035217\n",
      "epoch:  7, loss: 0.03048025816679001\n",
      "epoch:  8, loss: 0.025021716952323914\n",
      "epoch:  9, loss: 0.008223396725952625\n",
      "epoch:  10, loss: 0.0037970212288200855\n",
      "epoch:  11, loss: 0.002330662216991186\n",
      "epoch:  12, loss: 0.0017099428223446012\n",
      "epoch:  13, loss: 0.0013892464339733124\n",
      "epoch:  14, loss: 0.0011930714827030897\n",
      "epoch:  15, loss: 0.001064147800207138\n",
      "epoch:  16, loss: 0.0009652139851823449\n",
      "epoch:  17, loss: 0.0008756962488405406\n",
      "epoch:  18, loss: 0.0006279463996179402\n",
      "epoch:  19, loss: 0.0005255608120933175\n",
      "epoch:  20, loss: 0.00047610924229957163\n",
      "epoch:  21, loss: 0.00044054267345927656\n",
      "epoch:  22, loss: 0.00037718156818300486\n",
      "epoch:  23, loss: 0.00031402334570884705\n",
      "epoch:  24, loss: 0.0002850001910701394\n",
      "epoch:  25, loss: 0.0002655808930285275\n",
      "epoch:  26, loss: 0.00025474693393334746\n",
      "epoch:  27, loss: 0.0002526874013710767\n",
      "epoch:  28, loss: 0.00022340883151628077\n",
      "epoch:  29, loss: 0.00020710846001747996\n",
      "epoch:  30, loss: 0.00020684386254288256\n",
      "epoch:  31, loss: 0.00017929714522324502\n",
      "epoch:  32, loss: 0.0001671735808486119\n",
      "epoch:  33, loss: 0.0001607213489478454\n",
      "epoch:  34, loss: 0.000159326009452343\n",
      "epoch:  35, loss: 0.00014700586325488985\n",
      "epoch:  36, loss: 0.0001419084146618843\n",
      "epoch:  37, loss: 0.00013855693396180868\n",
      "epoch:  38, loss: 0.0001363940682495013\n",
      "epoch:  39, loss: 0.0001341143506579101\n",
      "epoch:  40, loss: 0.0001328676735283807\n",
      "epoch:  41, loss: 0.00013111300359014422\n",
      "epoch:  42, loss: 0.0001299205468967557\n",
      "epoch:  43, loss: 0.0001285468606511131\n",
      "epoch:  44, loss: 0.00012772236368618906\n",
      "epoch:  45, loss: 0.00012642020010389388\n",
      "epoch:  46, loss: 0.00012568225793074816\n",
      "epoch:  47, loss: 0.00012481212615966797\n",
      "epoch:  48, loss: 0.00012388735194690526\n",
      "epoch:  49, loss: 0.00012303043331485242\n",
      "epoch:  50, loss: 0.00012251496082171798\n",
      "epoch:  51, loss: 0.00012112607510061935\n",
      "epoch:  52, loss: 0.00011995920795015991\n",
      "epoch:  53, loss: 0.00011886467837030068\n",
      "epoch:  54, loss: 0.00011788181291194633\n",
      "epoch:  55, loss: 0.00011694673594320193\n",
      "epoch:  56, loss: 0.00011639270815066993\n",
      "epoch:  57, loss: 0.00011568740592338145\n",
      "epoch:  58, loss: 0.0001146629947470501\n",
      "epoch:  59, loss: 0.00011432799510657787\n",
      "epoch:  60, loss: 0.00011353465379215777\n",
      "epoch:  61, loss: 0.00011291019472992048\n",
      "epoch:  62, loss: 0.00011229762458242476\n",
      "epoch:  63, loss: 0.00011167021148139611\n",
      "epoch:  64, loss: 0.00011120835551992059\n",
      "epoch:  65, loss: 0.00011053286289097741\n",
      "epoch:  66, loss: 0.00010998201469192281\n",
      "epoch:  67, loss: 0.00010967519483529031\n",
      "epoch:  68, loss: 0.00010919748456217349\n",
      "epoch:  69, loss: 0.0001086274060071446\n",
      "epoch:  70, loss: 0.00010834583372343332\n",
      "epoch:  71, loss: 0.00010775790724437684\n",
      "epoch:  72, loss: 0.00010737759293988347\n",
      "epoch:  73, loss: 0.00010687675239751115\n",
      "epoch:  74, loss: 0.00010643841960700229\n",
      "epoch:  75, loss: 0.00010606216528685763\n",
      "epoch:  76, loss: 0.00010551594459684566\n",
      "epoch:  77, loss: 0.00010545678378548473\n",
      "epoch:  78, loss: 0.00010534915782045573\n",
      "epoch:  79, loss: 0.00010486382961971685\n",
      "epoch:  80, loss: 0.00010444702638778836\n",
      "epoch:  81, loss: 0.00010409906826680526\n",
      "epoch:  82, loss: 0.00010370193922426552\n",
      "epoch:  83, loss: 0.0001033271400956437\n",
      "epoch:  84, loss: 0.00010287675831932575\n",
      "epoch:  85, loss: 0.00010257700341753662\n",
      "epoch:  86, loss: 0.00010232422209810466\n",
      "epoch:  87, loss: 0.00010182780533796176\n",
      "epoch:  88, loss: 0.00010152553295483813\n",
      "epoch:  89, loss: 0.00010128068970516324\n",
      "epoch:  90, loss: 0.00010095423931488767\n",
      "epoch:  91, loss: 0.0001004633741104044\n",
      "epoch:  92, loss: 0.00010012226994149387\n",
      "epoch:  93, loss: 9.960155875887722e-05\n",
      "epoch:  94, loss: 9.950516687240452e-05\n",
      "epoch:  95, loss: 9.904585022013634e-05\n",
      "epoch:  96, loss: 9.862732258625329e-05\n",
      "epoch:  97, loss: 9.854311065282673e-05\n",
      "epoch:  98, loss: 9.812125790631399e-05\n",
      "epoch:  99, loss: 9.807129390537739e-05\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.1, line_search_method=\"backtrack\", line_search_cond=\"armijo\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"strong-wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"goldstein\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9970758641683755\n",
      "Test metrics:  R2 = 0.9850608917568883\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisection Line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.24122892320156097\n",
      "epoch:  1, loss: 0.06370922923088074\n",
      "epoch:  2, loss: 0.05481192097067833\n",
      "epoch:  3, loss: 0.03100678138434887\n",
      "epoch:  4, loss: 0.020260978490114212\n",
      "epoch:  5, loss: 0.015926534309983253\n",
      "epoch:  6, loss: 0.010537773370742798\n",
      "epoch:  7, loss: 0.008579334244132042\n",
      "epoch:  8, loss: 0.0066173505038022995\n",
      "epoch:  9, loss: 0.004721648525446653\n",
      "epoch:  10, loss: 0.0036226711235940456\n",
      "epoch:  11, loss: 0.0030223005451261997\n",
      "epoch:  12, loss: 0.002677768236026168\n",
      "epoch:  13, loss: 0.0023684590123593807\n",
      "epoch:  14, loss: 0.002075226977467537\n",
      "epoch:  15, loss: 0.001895594410598278\n",
      "epoch:  16, loss: 0.001782854087650776\n",
      "epoch:  17, loss: 0.0016814726404845715\n",
      "epoch:  18, loss: 0.0016071621794253588\n",
      "epoch:  19, loss: 0.001517284195870161\n",
      "epoch:  20, loss: 0.0014546114252880216\n",
      "epoch:  21, loss: 0.0013912329450249672\n",
      "epoch:  22, loss: 0.0013421373441815376\n",
      "epoch:  23, loss: 0.0012947340728715062\n",
      "epoch:  24, loss: 0.0012718832585960627\n",
      "epoch:  25, loss: 0.001229461980983615\n",
      "epoch:  26, loss: 0.0011906117433682084\n",
      "epoch:  27, loss: 0.0011506184237077832\n",
      "epoch:  28, loss: 0.0011249770177528262\n",
      "epoch:  29, loss: 0.0010900250636041164\n",
      "epoch:  30, loss: 0.001057529472745955\n",
      "epoch:  31, loss: 0.001035391353070736\n",
      "epoch:  32, loss: 0.001007702900096774\n",
      "epoch:  33, loss: 0.000995649374090135\n",
      "epoch:  34, loss: 0.0009693463216535747\n",
      "epoch:  35, loss: 0.0009316517971456051\n",
      "epoch:  36, loss: 0.0009096750873140991\n",
      "epoch:  37, loss: 0.0008894263883121312\n",
      "epoch:  38, loss: 0.0008712452836334705\n",
      "epoch:  39, loss: 0.0008615559199824929\n",
      "epoch:  40, loss: 0.000849531905259937\n",
      "epoch:  41, loss: 0.0008388090645894408\n",
      "epoch:  42, loss: 0.0008264739881269634\n",
      "epoch:  43, loss: 0.0008157987031154335\n",
      "epoch:  44, loss: 0.0008066050941124558\n",
      "epoch:  45, loss: 0.000796901120338589\n",
      "epoch:  46, loss: 0.0007863679784350097\n",
      "epoch:  47, loss: 0.0007768906652927399\n",
      "epoch:  48, loss: 0.000771228049416095\n",
      "epoch:  49, loss: 0.0007654145592823625\n",
      "epoch:  50, loss: 0.0007620969554409385\n",
      "epoch:  51, loss: 0.0007559640216641128\n",
      "epoch:  52, loss: 0.0007479953928850591\n",
      "epoch:  53, loss: 0.0007435223669745028\n",
      "epoch:  54, loss: 0.0007393627893179655\n",
      "epoch:  55, loss: 0.0007342361495830119\n",
      "epoch:  56, loss: 0.0007313084788620472\n",
      "epoch:  57, loss: 0.0007282824954017997\n",
      "epoch:  58, loss: 0.000723924720659852\n",
      "epoch:  59, loss: 0.0007199093815870583\n",
      "epoch:  60, loss: 0.0007162324618548155\n",
      "epoch:  61, loss: 0.0007146734278649092\n",
      "epoch:  62, loss: 0.0007125014089979231\n",
      "epoch:  63, loss: 0.000711131258867681\n",
      "epoch:  64, loss: 0.0007098420755937696\n",
      "epoch:  65, loss: 0.0007081005605868995\n",
      "epoch:  66, loss: 0.0007062221993692219\n",
      "epoch:  67, loss: 0.0007048076950013638\n",
      "epoch:  68, loss: 0.0007040225900709629\n",
      "epoch:  69, loss: 0.000702885736245662\n",
      "epoch:  70, loss: 0.0007020633202046156\n",
      "epoch:  71, loss: 0.0007014594739302993\n",
      "epoch:  72, loss: 0.0007005378138273954\n",
      "epoch:  73, loss: 0.0006990183028392494\n",
      "epoch:  74, loss: 0.0006982633494772017\n",
      "epoch:  75, loss: 0.0006973648560233414\n",
      "epoch:  76, loss: 0.0006961881299503148\n",
      "epoch:  77, loss: 0.000695215305313468\n",
      "epoch:  78, loss: 0.000694270886015147\n",
      "epoch:  79, loss: 0.0006933960248716176\n",
      "epoch:  80, loss: 0.0006927055073902011\n",
      "epoch:  81, loss: 0.0006922995089553297\n",
      "epoch:  82, loss: 0.0006916620768606663\n",
      "epoch:  83, loss: 0.0006906308117322624\n",
      "epoch:  84, loss: 0.0006897810962982476\n",
      "epoch:  85, loss: 0.0006891270168125629\n",
      "epoch:  86, loss: 0.0006884617614559829\n",
      "epoch:  87, loss: 0.0006877618143334985\n",
      "epoch:  88, loss: 0.0006874932441860437\n",
      "epoch:  89, loss: 0.0006871293298900127\n",
      "epoch:  90, loss: 0.0006866016774438322\n",
      "epoch:  91, loss: 0.0006862555164843798\n",
      "epoch:  92, loss: 0.0006858102278783917\n",
      "epoch:  93, loss: 0.0006848280318081379\n",
      "epoch:  94, loss: 0.0006843014270998538\n",
      "epoch:  95, loss: 0.0006838563131168485\n",
      "epoch:  96, loss: 0.0006833584629930556\n",
      "epoch:  97, loss: 0.0006829372723586857\n",
      "epoch:  98, loss: 0.00068264378933236\n",
      "epoch:  99, loss: 0.0006821342394687235\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.1, line_search_method=\"backtrack\", line_search_cond=\"armijo\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"strong-wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"goldstein\")\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, line_search_method=\"bisect\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.9791339730076761\n",
      "Test metrics:  R2 = 0.8724100689172414\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).detach()\n",
    "pred_test = model.forward(X_test).detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train)}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_numopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
