{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch_numopt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import *\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, device=\"cpu\"):\n",
    "        super().__init__()\n",
    "        self.f1 = nn.Linear(input_size, 10, device=device)\n",
    "        self.f2 = nn.Linear(10, 20, device=device)\n",
    "        self.f3 = nn.Linear(20, 20, device=device)\n",
    "        self.f4 = nn.Linear(20, 10, device=device)\n",
    "        self.f5 = nn.Linear(10, 1, device=device)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "        # self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.f1(x))\n",
    "        x = self.activation(self.f2(x))\n",
    "        x = self.activation(self.f3(x))\n",
    "        x = self.activation(self.f4(x))\n",
    "        x = self.f5(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 10]) torch.Size([800, 1])\n",
      "torch.Size([200, 10]) torch.Size([200, 1])\n"
     ]
    }
   ],
   "source": [
    "# X, y = load_diabetes(return_X_y=True, scaled=False)\n",
    "# X, y = make_regression(n_samples=1000, n_features=100)\n",
    "X, y = make_friedman1(n_samples=1000, noise=1e-2)\n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "X = X_scaler.fit_transform(X)\n",
    "X = torch.Tensor(X).to(device)\n",
    "\n",
    "y_scaler = MinMaxScaler()\n",
    "y = y_scaler.fit_transform(y.reshape((-1, 1)))\n",
    "y = torch.Tensor(y).to(device)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "torch_data = TensorDataset(X_train, y_train)\n",
    "data_loader = DataLoader(torch_data, batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Line Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.07094807922840118\n",
      "epoch:  1, loss: 0.07073919475078583\n",
      "epoch:  2, loss: 0.06263881921768188\n",
      "epoch:  3, loss: 0.05328408256173134\n",
      "epoch:  4, loss: 0.04686925932765007\n",
      "epoch:  5, loss: 0.042571764439344406\n",
      "epoch:  6, loss: 0.0376533605158329\n",
      "epoch:  7, loss: 0.033686183393001556\n",
      "epoch:  8, loss: 0.029170960187911987\n",
      "epoch:  9, loss: 0.025123022496700287\n",
      "epoch:  10, loss: 0.022134754806756973\n",
      "epoch:  11, loss: 0.01996367797255516\n",
      "epoch:  12, loss: 0.018057124689221382\n",
      "epoch:  13, loss: 0.017203230410814285\n",
      "epoch:  14, loss: 0.015816818922758102\n",
      "epoch:  15, loss: 0.014692587777972221\n",
      "epoch:  16, loss: 0.013666029088199139\n",
      "epoch:  17, loss: 0.01296538207679987\n",
      "epoch:  18, loss: 0.012154581025242805\n",
      "epoch:  19, loss: 0.011442584916949272\n",
      "epoch:  20, loss: 0.010801419615745544\n",
      "epoch:  21, loss: 0.01023920252919197\n",
      "epoch:  22, loss: 0.009737319312989712\n",
      "epoch:  23, loss: 0.00929289311170578\n",
      "epoch:  24, loss: 0.008897455409169197\n",
      "epoch:  25, loss: 0.008433111011981964\n",
      "epoch:  26, loss: 0.008138847537338734\n",
      "epoch:  27, loss: 0.007865610532462597\n",
      "epoch:  28, loss: 0.0076189665123820305\n",
      "epoch:  29, loss: 0.0073927100747823715\n",
      "epoch:  30, loss: 0.007182382047176361\n",
      "epoch:  31, loss: 0.006992741487920284\n",
      "epoch:  32, loss: 0.0123280119150877\n",
      "epoch:  33, loss: 0.01159671600908041\n",
      "epoch:  34, loss: 0.010940379463136196\n",
      "epoch:  35, loss: 0.010349209420382977\n",
      "epoch:  36, loss: 0.009828484617173672\n",
      "epoch:  37, loss: 0.009364035911858082\n",
      "epoch:  38, loss: 0.008944717235863209\n",
      "epoch:  39, loss: 0.008550399914383888\n",
      "epoch:  40, loss: 0.008203868754208088\n",
      "epoch:  41, loss: 0.007898153737187386\n",
      "epoch:  42, loss: 0.007618739269673824\n",
      "epoch:  43, loss: 0.007358138915151358\n",
      "epoch:  44, loss: 0.00712672621011734\n",
      "epoch:  45, loss: 0.006899374071508646\n",
      "epoch:  46, loss: 0.006701950915157795\n",
      "epoch:  47, loss: 0.0065258764661848545\n",
      "epoch:  48, loss: 0.006364905741065741\n",
      "epoch:  49, loss: 0.006219352129846811\n",
      "epoch:  50, loss: 0.006087394896894693\n",
      "epoch:  51, loss: 0.00596986897289753\n",
      "epoch:  52, loss: 0.00586070166900754\n",
      "epoch:  53, loss: 0.005758714396506548\n",
      "epoch:  54, loss: 0.00566505640745163\n",
      "epoch:  55, loss: 0.0055811055935919285\n",
      "epoch:  56, loss: 0.0055051506496965885\n",
      "epoch:  57, loss: 0.005431346595287323\n",
      "epoch:  58, loss: 0.00536341592669487\n",
      "epoch:  59, loss: 0.00530181173235178\n",
      "epoch:  60, loss: 0.005242261569947004\n",
      "epoch:  61, loss: 0.005185446236282587\n",
      "epoch:  62, loss: 0.005132467485964298\n",
      "epoch:  63, loss: 0.00508143613114953\n",
      "epoch:  64, loss: 0.00503188231959939\n",
      "epoch:  65, loss: 0.0049831802025437355\n",
      "epoch:  66, loss: 0.0049369847401976585\n",
      "epoch:  67, loss: 0.004891577176749706\n",
      "epoch:  68, loss: 0.0048469845205545425\n",
      "epoch:  69, loss: 0.004804236348718405\n",
      "epoch:  70, loss: 0.004761557560414076\n",
      "epoch:  71, loss: 0.004721174947917461\n",
      "epoch:  72, loss: 0.004683397710323334\n",
      "epoch:  73, loss: 0.004645739682018757\n",
      "epoch:  74, loss: 0.004610017873346806\n",
      "epoch:  75, loss: 0.004576855339109898\n",
      "epoch:  76, loss: 0.004542985465377569\n",
      "epoch:  77, loss: 0.0045112972147762775\n",
      "epoch:  78, loss: 0.004479968920350075\n",
      "epoch:  79, loss: 0.004449793603271246\n",
      "epoch:  80, loss: 0.004419740289449692\n",
      "epoch:  81, loss: 0.004392447415739298\n",
      "epoch:  82, loss: 0.004365108907222748\n",
      "epoch:  83, loss: 0.004335237666964531\n",
      "epoch:  84, loss: 0.0043080816976726055\n",
      "epoch:  85, loss: 0.004280800931155682\n",
      "epoch:  86, loss: 0.004253866150975227\n",
      "epoch:  87, loss: 0.004228502046316862\n",
      "epoch:  88, loss: 0.0042025251314044\n",
      "epoch:  89, loss: 0.004177629482001066\n",
      "epoch:  90, loss: 0.004153145477175713\n",
      "epoch:  91, loss: 0.00412959698587656\n",
      "epoch:  92, loss: 0.004940032958984375\n",
      "epoch:  93, loss: 0.004779920447617769\n",
      "epoch:  94, loss: 0.004644916392862797\n",
      "epoch:  95, loss: 0.004527298733592033\n",
      "epoch:  96, loss: 0.004427661653608084\n",
      "epoch:  97, loss: 0.00433971406891942\n",
      "epoch:  98, loss: 0.004260991234332323\n",
      "epoch:  99, loss: 0.004192236345261335\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=0.01, line_search_method=\"const\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.8602228165972577\n",
      "Test metrics:  R2 = 0.7169409821393211\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backtracking Line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.20084208250045776\n",
      "epoch:  1, loss: 0.16193899512290955\n",
      "epoch:  2, loss: 0.13151630759239197\n",
      "epoch:  3, loss: 0.11025375127792358\n",
      "epoch:  4, loss: 0.09014838933944702\n",
      "epoch:  5, loss: 0.07248212397098541\n",
      "epoch:  6, loss: 0.06264548003673553\n",
      "epoch:  7, loss: 0.0562414713203907\n",
      "epoch:  8, loss: 0.04392985254526138\n",
      "epoch:  9, loss: 0.03789079561829567\n",
      "epoch:  10, loss: 0.03386625647544861\n",
      "epoch:  11, loss: 0.017122888937592506\n",
      "epoch:  12, loss: 0.011662391945719719\n",
      "epoch:  13, loss: 0.011443219147622585\n",
      "epoch:  14, loss: 0.011242805048823357\n",
      "epoch:  15, loss: 0.011061047203838825\n",
      "epoch:  16, loss: 0.010904776863753796\n",
      "epoch:  17, loss: 0.00961024034768343\n",
      "epoch:  18, loss: 0.008927300572395325\n",
      "epoch:  19, loss: 0.008174488320946693\n",
      "epoch:  20, loss: 0.007604735903441906\n",
      "epoch:  21, loss: 0.007157898973673582\n",
      "epoch:  22, loss: 0.006742303259670734\n",
      "epoch:  23, loss: 0.006435425020754337\n",
      "epoch:  24, loss: 0.0061398763209581375\n",
      "epoch:  25, loss: 0.0059205880388617516\n",
      "epoch:  26, loss: 0.005887527950108051\n",
      "epoch:  27, loss: 0.005857516545802355\n",
      "epoch:  28, loss: 0.005857218522578478\n",
      "epoch:  29, loss: 0.005686943884938955\n",
      "epoch:  30, loss: 0.005528164561837912\n",
      "epoch:  31, loss: 0.005405965726822615\n",
      "epoch:  32, loss: 0.005266579333692789\n",
      "epoch:  33, loss: 0.005244732368737459\n",
      "epoch:  34, loss: 0.005227165762335062\n",
      "epoch:  35, loss: 0.005210499279201031\n",
      "epoch:  36, loss: 0.00511130690574646\n",
      "epoch:  37, loss: 0.0050790272653102875\n",
      "epoch:  38, loss: 0.0049827322363853455\n",
      "epoch:  39, loss: 0.004914049059152603\n",
      "epoch:  40, loss: 0.004848623648285866\n",
      "epoch:  41, loss: 0.004764513112604618\n",
      "epoch:  42, loss: 0.0047508892603218555\n",
      "epoch:  43, loss: 0.004688008688390255\n",
      "epoch:  44, loss: 0.0046274191699922085\n",
      "epoch:  45, loss: 0.00459596561267972\n",
      "epoch:  46, loss: 0.00458079669624567\n",
      "epoch:  47, loss: 0.00454341946169734\n",
      "epoch:  48, loss: 0.00449764309450984\n",
      "epoch:  49, loss: 0.004487004596740007\n",
      "epoch:  50, loss: 0.004441168624907732\n",
      "epoch:  51, loss: 0.004409602377563715\n",
      "epoch:  52, loss: 0.0043877302668988705\n",
      "epoch:  53, loss: 0.004350666422396898\n",
      "epoch:  54, loss: 0.004322275053709745\n",
      "epoch:  55, loss: 0.004304343368858099\n",
      "epoch:  56, loss: 0.004301891662180424\n",
      "epoch:  57, loss: 0.004267557058483362\n",
      "epoch:  58, loss: 0.004259216599166393\n",
      "epoch:  59, loss: 0.004232173785567284\n",
      "epoch:  60, loss: 0.004203930962830782\n",
      "epoch:  61, loss: 0.004180930554866791\n",
      "epoch:  62, loss: 0.00416540028527379\n",
      "epoch:  63, loss: 0.004148867446929216\n",
      "epoch:  64, loss: 0.004147983156144619\n",
      "epoch:  65, loss: 0.004139183554798365\n",
      "epoch:  66, loss: 0.004110609646886587\n",
      "epoch:  67, loss: 0.004093038383871317\n",
      "epoch:  68, loss: 0.004092165268957615\n",
      "epoch:  69, loss: 0.004083441570401192\n",
      "epoch:  70, loss: 0.004077264107763767\n",
      "epoch:  71, loss: 0.004064984619617462\n",
      "epoch:  72, loss: 0.004060595761984587\n",
      "epoch:  73, loss: 0.004034325946122408\n",
      "epoch:  74, loss: 0.004011814948171377\n",
      "epoch:  75, loss: 0.004009901080280542\n",
      "epoch:  76, loss: 0.004000673536211252\n",
      "epoch:  77, loss: 0.003988712560385466\n",
      "epoch:  78, loss: 0.003970334772020578\n",
      "epoch:  79, loss: 0.0039558131247758865\n",
      "epoch:  80, loss: 0.003926647361367941\n",
      "epoch:  81, loss: 0.00392575329169631\n",
      "epoch:  82, loss: 0.003919146489351988\n",
      "epoch:  83, loss: 0.003909023944288492\n",
      "epoch:  84, loss: 0.00389538099989295\n",
      "epoch:  85, loss: 0.003890973050147295\n",
      "epoch:  86, loss: 0.0038600300904363394\n",
      "epoch:  87, loss: 0.0038549734745174646\n",
      "epoch:  88, loss: 0.003837019670754671\n",
      "epoch:  89, loss: 0.0038182176649570465\n",
      "epoch:  90, loss: 0.00379957421682775\n",
      "epoch:  91, loss: 0.003793438198044896\n",
      "epoch:  92, loss: 0.0037887017242610455\n",
      "epoch:  93, loss: 0.0037776546087116003\n",
      "epoch:  94, loss: 0.003770905314013362\n",
      "epoch:  95, loss: 0.0037667746655642986\n",
      "epoch:  96, loss: 0.0037616032641381025\n",
      "epoch:  97, loss: 0.0037604765966534615\n",
      "epoch:  98, loss: 0.0037445842754095793\n",
      "epoch:  99, loss: 0.0037343576550483704\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.1, line_search_method=\"backtrack\", line_search_cond=\"armijo\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"strong-wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"goldstein\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.8838890850751601\n",
      "Test metrics:  R2 = 0.538304836613132\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bisection Line search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0, loss: 0.40123647451400757\n",
      "epoch:  1, loss: 0.35990622639656067\n",
      "epoch:  2, loss: 0.05912674590945244\n",
      "epoch:  3, loss: 0.028653740882873535\n",
      "epoch:  4, loss: 0.016193212941288948\n",
      "epoch:  5, loss: 0.012228498235344887\n",
      "epoch:  6, loss: 0.010191763751208782\n",
      "epoch:  7, loss: 0.009348577819764614\n",
      "epoch:  8, loss: 0.00750616192817688\n",
      "epoch:  9, loss: 0.006780543830245733\n",
      "epoch:  10, loss: 0.005453215911984444\n",
      "epoch:  11, loss: 0.004122577141970396\n",
      "epoch:  12, loss: 0.0035072064492851496\n",
      "epoch:  13, loss: 0.002601299434900284\n",
      "epoch:  14, loss: 0.002207098761573434\n",
      "epoch:  15, loss: 0.001885295263491571\n",
      "epoch:  16, loss: 0.0017658089054748416\n",
      "epoch:  17, loss: 0.001580837881192565\n",
      "epoch:  18, loss: 0.0014616461703553796\n",
      "epoch:  19, loss: 0.0013719871640205383\n",
      "epoch:  20, loss: 0.0012632940197363496\n",
      "epoch:  21, loss: 0.00125051976647228\n",
      "epoch:  22, loss: 0.0011980141280218959\n",
      "epoch:  23, loss: 0.001125263050198555\n",
      "epoch:  24, loss: 0.001077914610505104\n",
      "epoch:  25, loss: 0.0010334759717807174\n",
      "epoch:  26, loss: 0.0010058864718303084\n",
      "epoch:  27, loss: 0.000974360213149339\n",
      "epoch:  28, loss: 0.0009447954362258315\n",
      "epoch:  29, loss: 0.0009220283245667815\n",
      "epoch:  30, loss: 0.0008920333930291235\n",
      "epoch:  31, loss: 0.0008632165263406932\n",
      "epoch:  32, loss: 0.0008449330925941467\n",
      "epoch:  33, loss: 0.0008139088749885559\n",
      "epoch:  34, loss: 0.0007826249347999692\n",
      "epoch:  35, loss: 0.000757003843318671\n",
      "epoch:  36, loss: 0.0007406806689687073\n",
      "epoch:  37, loss: 0.0007149282027967274\n",
      "epoch:  38, loss: 0.0006952277617529035\n",
      "epoch:  39, loss: 0.0006837776163592935\n",
      "epoch:  40, loss: 0.0006656083860434592\n",
      "epoch:  41, loss: 0.000651856476906687\n",
      "epoch:  42, loss: 0.0006394934607669711\n",
      "epoch:  43, loss: 0.000630540365818888\n",
      "epoch:  44, loss: 0.0006274774787016213\n",
      "epoch:  45, loss: 0.0006209602579474449\n",
      "epoch:  46, loss: 0.0006181741482578218\n",
      "epoch:  47, loss: 0.000613070500548929\n",
      "epoch:  48, loss: 0.0006091437535360456\n",
      "epoch:  49, loss: 0.0006052008247934282\n",
      "epoch:  50, loss: 0.0006041564047336578\n",
      "epoch:  51, loss: 0.0006113555864430964\n",
      "epoch:  52, loss: 0.0005963517469353974\n",
      "epoch:  53, loss: 0.0005817146738991141\n",
      "epoch:  54, loss: 0.0005507820169441402\n",
      "epoch:  55, loss: 0.0005382628878578544\n",
      "epoch:  56, loss: 0.000532809121068567\n",
      "epoch:  57, loss: 0.0005294520524330437\n",
      "epoch:  58, loss: 0.0005189269431866705\n",
      "epoch:  59, loss: 0.0005155925173312426\n",
      "epoch:  60, loss: 0.0005134978564456105\n",
      "epoch:  61, loss: 0.0005110632046125829\n",
      "epoch:  62, loss: 0.0005092750652693212\n",
      "epoch:  63, loss: 0.000507679651491344\n",
      "epoch:  64, loss: 0.0005069662583991885\n",
      "epoch:  65, loss: 0.0005057636299170554\n",
      "epoch:  66, loss: 0.0005052667111158371\n",
      "epoch:  67, loss: 0.0005049444735050201\n",
      "epoch:  68, loss: 0.0005038559320382774\n",
      "epoch:  69, loss: 0.0005035126814618707\n",
      "epoch:  70, loss: 0.000519419030752033\n",
      "epoch:  71, loss: 0.0004887358518317342\n",
      "epoch:  72, loss: 0.00046534306602552533\n",
      "epoch:  73, loss: 0.0004495062166824937\n",
      "epoch:  74, loss: 0.00044046054244972765\n",
      "epoch:  75, loss: 0.000433616922236979\n",
      "epoch:  76, loss: 0.0004230774356983602\n",
      "epoch:  77, loss: 0.0004156002542003989\n",
      "epoch:  78, loss: 0.00041213727672584355\n",
      "epoch:  79, loss: 0.00040870122029446065\n",
      "epoch:  80, loss: 0.00040753616485744715\n",
      "epoch:  81, loss: 0.00040442662429995835\n",
      "epoch:  82, loss: 0.00040148160769604146\n",
      "epoch:  83, loss: 0.00039904890581965446\n",
      "epoch:  84, loss: 0.0003969634708482772\n",
      "epoch:  85, loss: 0.00039428373565897346\n",
      "epoch:  86, loss: 0.00039277292671613395\n",
      "epoch:  87, loss: 0.00038744485937058926\n",
      "epoch:  88, loss: 0.0003864130412694067\n",
      "epoch:  89, loss: 0.00038173460052348673\n",
      "epoch:  90, loss: 0.0003807531902566552\n",
      "epoch:  91, loss: 0.00037949284887872636\n",
      "epoch:  92, loss: 0.0003789174952544272\n",
      "epoch:  93, loss: 0.0003789548354689032\n",
      "epoch:  94, loss: 0.0003701231034938246\n",
      "epoch:  95, loss: 0.0003665815165732056\n",
      "epoch:  96, loss: 0.0003625117533374578\n",
      "epoch:  97, loss: 0.00035815767478197813\n",
      "epoch:  98, loss: 0.00034741839044727385\n",
      "epoch:  99, loss: 0.00033803682890720665\n"
     ]
    }
   ],
   "source": [
    "model = Net(input_size=X.shape[1], device=device)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.1, line_search_method=\"backtrack\", line_search_cond=\"armijo\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"strong-wolfe\")\n",
    "# opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, c1=1e-4, tau=0.5, line_search_method=\"backtrack\", line_search_cond=\"goldstein\")\n",
    "opt = torch_numopt.NewtonRaphson(params=model.parameters(), model=model, lr=1, line_search_method=\"bisect\")\n",
    "\n",
    "all_loss = {}\n",
    "for epoch in range(100):\n",
    "    print(\"epoch: \", epoch, end=\"\")\n",
    "    all_loss[epoch + 1] = 0\n",
    "    for batch_idx, (b_x, b_y) in enumerate(data_loader):\n",
    "        pre = model(b_x)\n",
    "        loss = loss_fn(pre, b_y)\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update step based on optimizer\n",
    "        opt.step(b_x, b_y, loss_fn)\n",
    "\n",
    "        all_loss[epoch + 1] += loss\n",
    "    all_loss[epoch + 1] /= len(data_loader)\n",
    "    print(\", loss: {}\".format(all_loss[epoch + 1].cpu().detach().numpy().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: R2 = 0.990648005655829\n",
      "Test metrics:  R2 = 0.8949833603702978\n"
     ]
    }
   ],
   "source": [
    "pred_train = model.forward(X_train).cpu().detach()\n",
    "pred_test = model.forward(X_test).cpu().detach()\n",
    "print(f\"Train metrics: R2 = {r2_score(pred_train, y_train.cpu())}\")\n",
    "print(f\"Test metrics:  R2 = {r2_score(pred_test, y_test.cpu())}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_numopt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
